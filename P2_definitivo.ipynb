{"cells":[{"cell_type":"markdown","metadata":{"id":"8hmGKkoYrwjN"},"source":["<div class=\"frontmatter\">\n","    <div style=\"display: flex; align-items: flex-start; justify-content: space-between;\">\n","        <div>\n","             <h1 style=\"font-weight: bold;\">Práctica 2: ESDA</h1>\n","            <h2>Autores: David Cantó, Roberto Rodero</h2>\n","            <h3>Máster en Tecnologías de la Información Geográfica, UAH</h3>\n","            <h3>Asignatura: Programación Avanzada</h3>\n","        </div>\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"bJkKhk2zRsHa"},"source":["# **Análisis de delitos y criminalidad en áreas urbanas**"]},{"cell_type":"markdown","metadata":{"id":"gUenICLIYXvc"},"source":["## **1. Introducción**"]},{"cell_type":"markdown","metadata":{"id":"crLkhODYVkXd"},"source":["### **Contexto**\n","La criminalidad en entornos urbanos es un fenómeno complejo influenciado por diversos factores socioeconómicos y espaciales. Comprender la distribución geográfica de los delitos es esencial para el diseño de estrategias de prevención y respuesta por parte de las autoridades. Este trabajo tiene como objetivo analizar los delitos cometidos en los distritos de la ciudad de Madrid, enfocándose en diversas categorías, como la seguridad ciudadana, el número de personas detenidas, los atestados y partes de accidentes, el consumo de alcohol en la vía pública, y las inspecciones y actuaciones en locales de espectáculos públicos y actividades recreativas, así como las multas de tráfico.\n","\n","El análisis espacial permitirá identificar patrones y tendencias de criminalidad, contribuyendo a una mejor comprensión de estos fenómenos y proporcionando información útil para la toma de decisiones de seguridad y políticas públicas en este sentido.\n","\n","## **Objetivos**\n","- Analizar la distribución geográfica de los delitos y las multas de tráfico en los distritos de Madrid y su evolución durante la última década.\n","- Evaluar la relación entre la densidad de población y la criminalidad en los distritos de Madrid.\n","- Generar cartografía y gráficos estadísticos que ayuden a comprender estos fenómenos.\n","\n","## **Preguntas clave**\n","1. ¿Existe correlación espacial en los delitos de la Comunidad de Madrid?\n","2. ¿En el caso de que exista, de que tipo es?\n","3. ¿Cuáles son las áreas de Madrid con mayor número de multas de tráfico?\n","4. ¿Si agrupamos los distritos de Madrid según el número de delitos, adquieren una forma similar a las divisiones administrativas reales?"]},{"cell_type":"markdown","metadata":{"id":"KsgYC9PXR1D1"},"source":["## **2. Conjunto de datos**"]},{"cell_type":"markdown","metadata":{"id":"g6IcbCuSVk6r"},"source":["Para este estudio, se utilizarán datos públicos proporcionados por el Ayuntamiento de Madrid, a través del Portalde Datos Abiertos del Ayuntamiento de Madrid y se pueden consultar en el siguiente enlace:  [https://datos.madrid.es/sites/v/index.jsp?vgnextoid=bffff1d2a9fdb410VgnVCM2000000c205a0aRCRD&vgnextchannel=20d612b9ace9f310VgnVCM100000171f5a0aRCRD](https://datos.madrid.es/sites/v/index.jsp?vgnextoid=bffff1d2a9fdb410VgnVCM2000000c205a0aRCRD&vgnextchannel=20d612b9ace9f310VgnVCM100000171f5a0aRCRD). Los principales conjuntos de datos incluyen:\n","\n","- Delitos relacionados con la seguridad ciudadana:\n","  - Relacionados con las personas\n","  - Relacionadas con el patrimonio\n","  - Por tenencia de armas\n","  - Por tenencia de drogas\n","  - Por consumo de drogas\n","\n","- Personas detenidas e imputadas:\n","\n","- Partes de accidente confeccionados y atestados:\n","\n","- Consumo de alcohol en la vía pública:\n","\n","- Intervenciones por protección a los consumidores y usuarios en vía pública:\n","\n","- Inspecciones y actuaciones en locales de espectáculos públicos y actividades recreativas:\n","\n","- Capa de distritos de la ciudad de Madrid\n","\n","Se han utilizado datos de población por distritos, disponibles en el siguiente enlace: https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=0cccaebc07c1f710VgnVCM2000001f4a900aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default.\n","\n","Estos datos serán analizados en formato geoespacial (SHP, GeoJSON) y tabular (CSV, Excel), considerando su calidad, precisión y confiabilidad para garantizar resultados válidos.\n","\n","Por su parte, el archivo ráster a analizar es un ráster de zonas verdes de la ciudad de Madrid, disponible en: https://geoportal.madrid.es/IDEAM_WBGEOPORTAL/dataset.iam?id=53896e7f-8b6b-4cbc-a0aa-bfbeee91563e.\n","\n","En lo relativo a las estadísticas de las multas de tráfico en Madrid utilizadas para el análisis de patrones de puntos, se han obtenido en el siguiente enlace: https://datos.madrid.es/sites/v/index.jsp?vgnextoid=fb9a498a6bdb9410VgnVCM1000000b205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD."]},{"cell_type":"markdown","metadata":{"id":"lnp8KSJlR4TY"},"source":["## **3. Exploración y procesamiento de datos**"]},{"cell_type":"markdown","metadata":{"id":"VZmCnUVxcx-W"},"source":["En primer lugar se importaron los módulos y paquetes necesarios para poder explorar y procesar los conjuntos de datos con los que vamos a trabajar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y2whuOnvRkEU"},"outputs":[],"source":["!pip install rasterio\n","!pip install rasterstats\n","!pip install mapclassify\n","!pip install folium\n","!pip install mplcursors\n","!pip install pysal\n","!pip install libpysal\n","!pip install adjustText\n","!pip install contextily"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Md3pnrJRN1O5"},"outputs":[],"source":["from google.colab import drive\n","from google.colab import files\n","import os\n","import pandas as pd\n","import geopandas as gpd\n","import xarray as xr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import folium\n","import rasterio\n","from sklearn.cluster import KMeans\n","from scipy.cluster.hierarchy import dendrogram, linkage\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.metrics import silhouette_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.tree import plot_tree\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from rasterio.mask import mask\n","from rasterio.features import geometry_mask\n","from rasterstats import zonal_stats\n","import ipywidgets as widgets\n","from ipywidgets import interact\n","from IPython.display import display\n","from IPython.display import clear_output\n","import branca.colormap as cm\n","from sklearn.linear_model import LinearRegression\n","import warnings\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","import dask.array as da\n","import mapclassify\n","from shapely.geometry import Point\n","import pysal\n","import contextily as cx\n","from pointpats import distance_statistics\n","from ipywidgets import interact, fixed\n","from libpysal.weights import Queen\n","from pysal.lib import weights\n","from splot.libpysal import plot_spatial_weights\n","import matplotlib.patches as mpatches\n","import io\n","from adjustText import adjust_text\n","from pysal.explore import esda\n","from splot.esda import (\n","    moran_scatterplot, lisa_cluster, plot_local_autocorrelation, plot_moran\n",")"]},{"cell_type":"markdown","metadata":{"id":"KkqmuC-edLbH"},"source":["Una vez cargados los paquetes necesarios, preparamos la carpeta de google drive desde la que vamos a trabajar. Dentro de ella se encuentran los conjuntos de datos que vamos a utilizar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFIzuwgzPsn8"},"outputs":[],"source":["# Conectar a Google Drive para enlazar las carpetas almacenadas en Drive con los archivos necesarios\n","drive.mount('/content/drive')\n","# Establecer la ruta de la carpeta principal\n","folder = '/content/drive/My Drive/P1_Avanzada'\n","\n","# Listar las subcarpetas dentro de la carpeta principal\n","def listar_carpetas(carpeta):\n","    for name in os.listdir(carpeta):\n","        if os.path.isdir(os.path.join(carpeta, name)):\n","            print(name)\n","\n","listar_carpetas(folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8zLt0FYFO_-m"},"outputs":[],"source":["# Establecer la ruta que contiene las carpetas con los datos de delitos, distritos y ráster de zonas verdes.\n","datos_2015 = os.path.join(folder, 'Delitos_2015')\n","datos_2016 = os.path.join(folder, 'Delitos_2016')\n","datos_2017 = os.path.join(folder, 'Delitos_2017')\n","datos_2018 = os.path.join(folder, 'Delitos_2018')\n","datos_2019 = os.path.join(folder, 'Delitos_2019')\n","datos_2020 = os.path.join(folder, 'Delitos_2020')\n","datos_2021 = os.path.join(folder, 'Delitos_2021')\n","datos_2022 = os.path.join(folder, 'Delitos_2022')\n","datos_2023 = os.path.join(folder, 'Delitos_2023')\n","datos_2024 = os.path.join(folder, 'Delitos_2024')\n","distritos_shp = os.path.join(folder, 'Distritos_shape', 'DISTRITOS.shp')\n","poblacion = os.path.join(folder, 'Poblacion', 'poblacion_1_enero.csv')\n","Zonas_verdes_rast = os.path.join(folder, 'Zonas_verdes_rast', 'Zonas_verdes_30m.tif')\n","multas = os.path.join(folder, 'Multas_5_2024', '202405detalle.csv')"]},{"cell_type":"markdown","metadata":{"id":"ioozpq6zgTl9"},"source":["Una vez localizadas y seleccionadas las carpetas que contiene los conjuntos de datos con los que vamos a trabajar, comenzamos a modificar estos conjuntos de datos. Para ello, el primer paso es seleccionar únicamente las hojas dentro de los archivos excel que nos interesan. Después, creamos para cada archivo excel una columna que incluira la fecha del archivo, extrayendola a partir del nombre del mismo. Por último, concatenamos las diferentes hojas y archivos para obtener una base de datos con la que poder trabajar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wr6LjXOU3BBQ"},"outputs":[],"source":["# Lista de las hojas a leer de los arcchivos excel\n","hojas_a_leer = ['SEGURIDAD', 'DETENIDOS X DISTRITOS', 'ACCIDENTES', 'VENTA AMBULANTE', 'CONSUMO ALCOHOL', 'LOCALES']\n","\n","# Función para obtener los archivos Excel en una carpeta\n","def obtener_archivos_excel(carpeta):\n","    return [f for f in os.listdir(carpeta) if f.endswith('.xlsx') or f.endswith('.xls')]\n","\n","# Obtener los archivos Excel de las carpetas datos_2015 y datos_2024\n","archivos_2015 = obtener_archivos_excel(datos_2015)\n","archivos_2016 = obtener_archivos_excel(datos_2016)\n","archivos_2017 = obtener_archivos_excel(datos_2017)\n","archivos_2018 = obtener_archivos_excel(datos_2018)\n","archivos_2019 = obtener_archivos_excel(datos_2019)\n","archivos_2020 = obtener_archivos_excel(datos_2020)\n","archivos_2021 = obtener_archivos_excel(datos_2021)\n","archivos_2022 = obtener_archivos_excel(datos_2022)\n","archivos_2023 = obtener_archivos_excel(datos_2023)\n","archivos_2024 = obtener_archivos_excel(datos_2024)\n","\n","# Lista para almacenar los DataFrames de las hojas seleccionadas\n","todos_los_datos = []\n","\n","# Función para procesar los archivos de una carpeta y concatenar las hojas seleccionadas por columnas\n","def procesar_archivos(carpeta, archivos):\n","    for archivo in archivos:\n","        # Leer todas las hojas del archivo Excel\n","        xls = pd.ExcelFile(os.path.join(carpeta, archivo))\n","\n","        # Lista temporal para almacenar las hojas que se van a concatenar por columnas\n","        hojas_temporales = []\n","\n","        # Obtener el nombre correcto del archivo (sin el sufijo)\n","        nombre_archivo_correcto = archivo.split('.')[0]\n","\n","        # Variable para controlar si se está en la primera hoja\n","        es_primera_hoja = True\n","\n","        # Iterar sobre las hojas del archivo y leer solo las que están en la lista `hojas_a_leer`\n","        for nombre_hoja in xls.sheet_names:\n","            if nombre_hoja in hojas_a_leer:\n","                # Leer la hoja en un DataFrame, omitiendo las dos primeras filas\n","                df = pd.read_excel(xls, sheet_name=nombre_hoja, skiprows=2)\n","\n","                # Si es la primera hoja, añadir la columna 'Fecha' y 'Distritos' con el nombre del archivo\n","                if es_primera_hoja:\n","                    df['Fecha'] = nombre_archivo_correcto\n","\n","                if not es_primera_hoja:\n","                    df = df.iloc[:, 1:]  # Eliminar la primera columna\n","\n","                es_primera_hoja = False\n","\n","                # Añadir el DataFrame de la hoja a la lista temporal\n","                hojas_temporales.append(df)\n","\n","        # Si hay hojas seleccionadas para este archivo, concatenarlas por columnas\n","        if hojas_temporales:\n","            df_archivo = pd.concat(hojas_temporales, axis=1)\n","            # Añadir el DataFrame concatenado por columnas a la lista de todos los datos\n","            todos_los_datos.append(df_archivo)\n","\n","# Procesar los archivos de las carpetas 2015 y 2024\n","procesar_archivos(datos_2015, archivos_2015)\n","procesar_archivos(datos_2016, archivos_2016)\n","procesar_archivos(datos_2017, archivos_2017)\n","procesar_archivos(datos_2018, archivos_2018)\n","procesar_archivos(datos_2019, archivos_2019)\n","procesar_archivos(datos_2020, archivos_2020)\n","procesar_archivos(datos_2021, archivos_2021)\n","procesar_archivos(datos_2022, archivos_2022)\n","procesar_archivos(datos_2023, archivos_2023)\n","procesar_archivos(datos_2024, archivos_2024)\n","\n","# Concatenar todos los DataFrames de diferentes archivos Excel por filas\n","df_final = pd.concat(todos_los_datos, axis=0, ignore_index=True)"]},{"cell_type":"markdown","metadata":{"id":"osUKaKQ1I00L"},"source":["Después de esto, hacemos una primera exploración de los datos, para comprobar que se han unido correctamente las distintas hojas y excels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4WGbMOYdJYy"},"outputs":[],"source":["df_final.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD4ksj_Apj8D"},"outputs":[],"source":["df_final.info()"]},{"cell_type":"markdown","metadata":{"id":"he79bPUxRuRG"},"source":["Algunas variables contienen la misma información pero han recibido nombres diferentes. Por ello, lo primero que tenemos que hacer es concatenar los datos del mismo tipo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CUgJE-svR76t"},"outputs":[],"source":["# Selecciona las columnas que quieres combinar\n","columnas_a_combinar = ['CON HERIDOS', 'CON VICTIMAS']\n","\n","# Concatena las columnas seleccionadas\n","nueva_columna = pd.concat([df_final[col] for col in columnas_a_combinar], ignore_index=True)\n","\n","# Si quieres eliminar valores nulos antes de concatenar, puedes hacerlo así:\n","nueva_columna = pd.concat([df_final[col].dropna() for col in columnas_a_combinar], ignore_index=True)\n","\n","# Elimina las columnas originales si ya no las necesitas\n","df_final = df_final.drop(columns=columnas_a_combinar)\n","\n","# Luego, añade la nueva columna al GeoDataFrame\n","df_final['CON HERIDOS'] = nueva_columna\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0MrNxVlTErW"},"outputs":[],"source":["# Selecciona las columnas que quieres combinar\n","columnas_a_combinar = ['SIN HERIDOS', 'SIN VICTIMAS']\n","\n","# Concatena las columnas seleccionadas\n","nueva_columna = pd.concat([df_final[col] for col in columnas_a_combinar], ignore_index=True)\n","\n","# Si quieres eliminar valores nulos antes de concatenar, puedes hacerlo así:\n","nueva_columna = pd.concat([df_final[col].dropna() for col in columnas_a_combinar], ignore_index=True)\n","\n","# Elimina las columnas originales si ya no las necesitas\n","df_final = df_final.drop(columns=columnas_a_combinar)\n","\n","# Luego, añade la nueva columna al GeoDataFrame\n","df_final['SIN HERIDOS'] = nueva_columna\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpp7SBJyTVC1"},"outputs":[],"source":["# Selecciona las columnas que quieres combinar\n","columnas_a_combinar = ['ADULTOS', 'MAYORES DE EDAD']\n","\n","# Concatena las columnas seleccionadas\n","nueva_columna = pd.concat([df_final[col] for col in columnas_a_combinar], ignore_index=True)\n","\n","# Si quieres eliminar valores nulos antes de concatenar, puedes hacerlo así:\n","nueva_columna = pd.concat([df_final[col].dropna() for col in columnas_a_combinar], ignore_index=True)\n","\n","# Elimina las columnas originales si ya no las necesitas\n","df_final = df_final.drop(columns=columnas_a_combinar)\n","\n","# Luego, añade la nueva columna al GeoDataFrame\n","df_final['ADULTOS'] = nueva_columna\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"och4nehwTlcO"},"outputs":[],"source":["# Selecciona las columnas que quieres combinar\n","columnas_a_combinar = ['MENORES', 'MENORES DE 18 AÑOS']\n","\n","# Concatena las columnas seleccionadas\n","nueva_columna = pd.concat([df_final[col] for col in columnas_a_combinar], ignore_index=True)\n","\n","# Si quieres eliminar valores nulos antes de concatenar, puedes hacerlo así:\n","nueva_columna = pd.concat([df_final[col].dropna() for col in columnas_a_combinar], ignore_index=True)\n","\n","# Elimina las columnas originales si ya no las necesitas\n","df_final = df_final.drop(columns=columnas_a_combinar)\n","\n","# Luego, añade la nueva columna al GeoDataFrame\n","df_final['MENORES'] = nueva_columna\n"]},{"cell_type":"markdown","metadata":{"id":"ZOfZXZ2SIdu0"},"source":["A continuación asignamos una variable para el shapefile que contiene las geometrías de los distritos. Después exploramos este shapefile para ver a partir de qué columnas podemos unir los datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XiJNoGTMXjaw"},"outputs":[],"source":["distritos = gpd.read_file(distritos_shp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HBUQEQVcZE-"},"outputs":[],"source":["print(distritos.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUAKu5Db2lBI"},"outputs":[],"source":["print(distritos.columns)"]},{"cell_type":"markdown","metadata":{"id":"e_xMq0uOnwb3"},"source":["Al comparar los datos del shapefile y la base de datos vemos que hay columnas que comparten información pero no se llaman igual, por lo que cambiamos el nombre de una del shapefile para realizar la unión."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfqwzXyrqhoi"},"outputs":[],"source":["# Renombrar la columna 'shapefile_ID' a 'df_ID' para que coincidan\n","distritos = distritos.rename(columns={'DISTRI_MT': 'DISTRITOS'})"]},{"cell_type":"markdown","metadata":{"id":"Q7-b-dzRoCqX"},"source":["Nos aseguramos que ambas columnas están en el mismo formato para realizar la unión."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQ6auZpk20Fu"},"outputs":[],"source":["df_final['DISTRITOS'] = df_final['DISTRITOS'].astype(str)\n","distritos['DISTRITOS'] = distritos['DISTRITOS'].astype(str)"]},{"cell_type":"markdown","metadata":{"id":"ymzo8B71oLov"},"source":["Realizamos la unión a partir de la columna que comparte información."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCXd57Gh1wA4"},"outputs":[],"source":["# Realizar la unión entre el DataFrame y el shapefile\n","df_union = df_final.merge(distritos[['DISTRITOS', 'geometry']], on='DISTRITOS', how='left')"]},{"cell_type":"markdown","metadata":{"id":"4pBFqZhRoeXX"},"source":["Una vez realizada la unión, comenzamos a modificar la base de datos para poder trabajar con ella. En primer lugar, generamos una columna de año y otra de mes a partir de la columna generada a partir del nombre de los archivos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1KW7LwTE3Oc"},"outputs":[],"source":["# Con este código separamos la columna fecha en dos nuevas columnas, año y mes.\n","df_union[['Mes', 'Año']] = df_union['Fecha'].str.split('_', expand=True)\n","\n","# Mostrar las primeras filas del GeoDataFrame con las nuevas columnas\n","print(df_union[['Fecha', 'Mes', 'Año']])"]},{"cell_type":"markdown","metadata":{"id":"sEO7fWbY0pKA"},"source":["Después generamos una columna con los meses como variable numérica. Tener la variable de meses de este modo puede llegar a ser útil de cara a algunas representaciones gráficas de los datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuaPSF6KApw1"},"outputs":[],"source":["# Diccionario que mapea los meses en palabras a su respectivo número\n","mes_a_numero = {\n","    'Enero': 1, 'Febrero': 2, 'Marzo': 3, 'Abril': 4, 'Mayo': 5, 'Junio': 6,\n","    'Julio': 7, 'Agosto': 8, 'Septiembre': 9, 'Octubre': 10, 'Noviembre': 11, 'Diciembre': 12\n","}\n","\n","# Convertir la columna 'mes' de nombre a número\n","df_union['mes'] = df_union['Mes'].map(mes_a_numero)"]},{"cell_type":"markdown","metadata":{"id":"Vla6niLr0-jQ"},"source":["A continuación, convertimos el data frame en un geodataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8pTK8I44Msg"},"outputs":[],"source":["# Asegurarse de que es un GeoDataFrame\n","df_union = gpd.GeoDataFrame(df_union, geometry='geometry')"]},{"cell_type":"markdown","metadata":{"id":"5zUkvHy3GGRl"},"source":["Después añadimos algunas columnas que podrían ser útiles a la hora de estudiar la base de datos, como el área de cada distrito."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuUsOPtaGF-u"},"outputs":[],"source":["df_union['Area'] = df_union.geometry.area # Por defecto se calcula el área en metros cuadrados\n","df_union['Area_ha'] = df_union['Area'] / 10000 # Área en hectáreas\n","df_union['Area_km2'] = df_union['Area'] / 1000000 # Área en kilómetros cuadrados\n"]},{"cell_type":"markdown","metadata":{"id":"1zA6WlmiHeJt"},"source":["Luego, eliminamos las columnas que no nos interesan de nuestra base de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JToQxNf-Hol9"},"outputs":[],"source":["#He puesto esto como ejemplo, pero se pueden poner otros o ninguno, depende de lo que acabemos haciendo.\n","df_union = df_union.drop(columns=['Fecha','DENUNCIAS','DETENIDOS E IMPUTADOS','DETENIDOS E INVESTIGADOS'])"]},{"cell_type":"markdown","metadata":{"id":"qswMhpfdkAfX"},"source":["Después de esto, incorporamos datos de población a nuestro dataframe. Como se puede ver a continuación, dan información sobre la población por distrito, lo cual podría ser una variable interesante a la hora de estudiar los delitos cometidos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k3bwMFVKkEm9"},"outputs":[],"source":["# Leer el archivo CSV y seleccionar las primeras 22 columnas, que son las que contienen los datos que nos interesan\n","df_poblacion = pd.read_csv(poblacion, sep=\";\").head(21)\n","\n","# Mostrar las primeras filas del DataFrame para verificar\n","df_poblacion.head()\n","df_poblacion.info()"]},{"cell_type":"markdown","metadata":{"id":"2gJJbyl_tOn4"},"source":["Después cambiamos el nombre de algunas columnas para que sea más facil trabajar con ellas en el futuro. Además, eliminamos las columnas que no nos interesan."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmHLthCOvuzq"},"outputs":[],"source":["# Cambiar nombres de algunas columnas para adecuarlos\n","df_poblacion = df_poblacion.rename(columns={'num_personas': 'poblacion'})\n","df_poblacion = df_poblacion.rename(columns={'num_personas_hombres': 'pob_hombres'})\n","df_poblacion = df_poblacion.rename(columns={'num_personas_mujeres': 'pob_mujeres'})\n","df_poblacion = df_poblacion.rename(columns={'distrito': 'DISTRITOS'})\n","\n","# Eliminar columnas que no resultan interesantes en el analisis\n","df_poblacion = df_poblacion.drop(columns=['fecha', 'cod_municipio', 'municipio',\n","                                          'cod_barrio', 'barrio'])"]},{"cell_type":"markdown","metadata":{"id":"2hAFoxX9t2Zq"},"source":["Antes de poder unir estos datos con el resto necesitamos modificar el nombre de la columna de distritos para que coincidan."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnFaKrYyxd9K"},"outputs":[],"source":["# Poner los nombres de los distritos en mayúsculas, también para manejar la unión\n","df_poblacion['DISTRITOS'] = df_poblacion['DISTRITOS'].str.upper()\n","df_poblacion['DISTRITOS'] = df_poblacion['DISTRITOS'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkV1ctlyx71g"},"outputs":[],"source":["# Eliminar espacios después de los guiones en los nombres de los distritos\n","# para mantener el mismo nombre y poder realizar la unión correctamente\n","df_poblacion['DISTRITOS'] = df_poblacion['DISTRITOS'].str.replace(r'\\s*-\\s*', '-', regex=True)\n","df_union['DISTRITOS'] = df_union['DISTRITOS'].str.replace(r'\\s*-\\s*', '-', regex=True)\n","\n","df_poblacion['DISTRITOS'] = df_poblacion['DISTRITOS'].str.strip().str.upper().str.replace(r'\\s*-\\s*', '-', regex=True)\n","df_union['DISTRITOS'] = df_union['DISTRITOS'].str.strip().str.upper().str.replace(r'\\s*-\\s*', '-', regex=True)"]},{"cell_type":"markdown","metadata":{"id":"pVHG8yVhzaoI"},"source":["Realizamos la unión y comprobamos que se ha realizado correctamente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZOg-Pr1OzAUx"},"outputs":[],"source":["df_union = df_union.merge(df_poblacion, on='DISTRITOS', how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdOZ6_MzzLPf"},"outputs":[],"source":["df_union.head()"]},{"cell_type":"markdown","metadata":{"id":"QzUNjJiP4XKY"},"source":["Después convertimos los datos de población a tipo numérico y calculamos la densidad de población (total, de hombres y de mujeres)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZVMY6hf4loh"},"outputs":[],"source":["# Convertir la columna 'Poblacion' a tipo numérico (por si tiene valores tipo str)\n","df_union['poblacion'] = pd.to_numeric(df_union['poblacion'], errors='coerce')\n","df_union['pob_hombres'] = pd.to_numeric(df_union['pob_hombres'], errors='coerce')\n","df_union['pob_mujeres'] = pd.to_numeric(df_union['pob_mujeres'], errors='coerce')\n","\n","# Calcular densidad de población\n","df_union['densidad_pob_km2'] = df_union['poblacion'] / df_union['Area_km2']\n","df_union['densidad_pob_ha'] = df_union['poblacion'] / df_union['Area_ha']\n","df_union['densidad_pob_hombres'] = df_union['pob_hombres'] / df_union['Area_km2']\n","df_union['densidad_pob_mujeres'] = df_union['pob_mujeres'] / df_union['Area_km2']\n","df_union['densidad_pob_hombres_ha'] = df_union['pob_hombres'] / df_union['Area_ha']\n","df_union['densidad_pob_mujeres_ha'] = df_union['pob_mujeres'] / df_union['Area_ha']"]},{"cell_type":"markdown","metadata":{"id":"eSH-5fT03Pj4"},"source":["Después pasamos a la limpieza de los datos. Para ello primero comprobamos si hay datos duplicados o valores nulos en nuestro dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tf9yp2g0Rf1C"},"outputs":[],"source":["#Este código muestra las filas duplicadas.\n","df_union[df_union.duplicated(keep='first')]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tR29MdIguHil"},"outputs":[],"source":["#Esta función nos permite saber si hay datos nulos\n","df_union.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"-Fz1rx8RE11_"},"source":["Como en las bases de datos originales había información sobre el total de la zona y sabiendo que estos datos no poseen geometrías y tampoco datos de población, aparecen como nulos. Por ello los eliminaremos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5C18WoCFBZG"},"outputs":[],"source":["df_union = df_union.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1ZewpTlsWXs"},"outputs":[],"source":["# Desactivar los warnings\n","warnings.simplefilter('ignore')\n","\n","# Nos aseguramos de que las columnas de 'Año' y 'mes' son de tipo string.\n","df_union['Año'] = df_union['Año'].astype(str)\n","df_union['mes'] = df_union['mes'].astype(str)\n","\n","# Crear una nueva columna combinada 'Año-Mes' para la animación.\n","df_union['Año-mes'] = df_union['Año'] + '-' + df_union['mes']\n","\n","# Convertir la columna 'Año-Mes' a tipo fecha para ordenar cronológicamente.\n","df_union['Fecha'] = pd.to_datetime(df_union['Año-mes'], format='%Y-%m')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75tgf3fgGu1I"},"outputs":[],"source":["df_union.head()"]},{"cell_type":"markdown","source":["Hasta aquí no hay ningún cambio respecto al EDA realizado con estos mismos datos, pero como nos interesa realizar también un análisis de patrones de puntos vamos a cargar otros datos. En este caso de multas en Madrid. Una vez cargados estos datos vamos a limpiarlos y modificarlos para poder trabajar con ellos"],"metadata":{"id":"5LWBlpwWo81O"}},{"cell_type":"markdown","source":["Primero establecemos la ruta del archivo y creamos un dataframe con los datos de multas."],"metadata":{"id":"jo7KNSjHyU6Q"}},{"cell_type":"code","source":["# Ruta del archivo CSV con los datos de multas de tráfico en mayo de 2024\n","multas = os.path.join(folder, 'Multas_5_2024', '202405detalle.csv')\n","\n","# Cargar el CSV con la codificación correcta\n","df_multas = pd.read_csv(multas, sep=';', encoding='ISO-8859-1', dtype={'COORDENADA-X': str, 'COORDENADA-Y': str})"],"metadata":{"id":"57QaZrpHydQA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Limpiamos los nombres de las columnas eliminando caracteres no deseados y también eliminamos valores nulos. Además convertimos las columnas de coordenadas a valores numéricos para poder trabajar con ellas."],"metadata":{"id":"00NckKPcyiBy"}},{"cell_type":"code","source":["# Limpiar nombres de columnas\n","df_multas.columns = df_multas.columns.str.strip()\n","\n","# Eliminar valores nulos o vacíos en 'COORDENADA-X' y 'COORDENADA-Y'\n","df_multas = df_multas.dropna(subset=['COORDENADA-X', 'COORDENADA-Y'])\n","df_multas = df_multas[(df_multas['COORDENADA-X'] != '') & (df_multas['COORDENADA-Y'] != '')]\n","\n","# Convertir coordenadas a tipo numérico\n","df_multas['COORDENADA-X'] = pd.to_numeric(df_multas['COORDENADA-X'], errors='coerce')\n","df_multas['COORDENADA-Y'] = pd.to_numeric(df_multas['COORDENADA-Y'], errors='coerce')\n","\n","# Eliminar posibles valores NaN generados\n","df_multas = df_multas.dropna(subset=['COORDENADA-X', 'COORDENADA-Y'])"],"metadata":{"id":"0thyVRs7yt8K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A continuación, creamos las geometrías de los puntos según las coordenadas del dataframe."],"metadata":{"id":"G5gOeFNVzNEC"}},{"cell_type":"code","source":["# Crear geometría de puntos con CRS 25830\n","geometry = gpd.points_from_xy(df_multas['COORDENADA-X'], df_multas['COORDENADA-Y'])\n","gdf_multas = gpd.GeoDataFrame(df_multas, geometry=geometry, crs=\"EPSG:25830\")"],"metadata":{"id":"PrmEzUlQzZBq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Recragamos la capa de distritos para que no cuente con las modificaciones que hemos realizado previamente, nos aseguramos de que el sistema de referencia de multas y distritos coincida y unimos los datos."],"metadata":{"id":"U0pmtpXLznqB"}},{"cell_type":"code","source":["# Cargar shapefile de distritos\n","distritos = gpd.read_file(distritos_shp)\n","\n","# Establecer mismo SRC para las dos capas (EPSG:4326)\n","gdf_multas = gdf_multas.to_crs(epsg=4326)\n","distritos = distritos.to_crs(epsg=4326)\n","\n","# Unión espacial para seleccionar solo las multas dentro de los distritos\n","gdf_multas = gpd.sjoin(gdf_multas, distritos, how=\"inner\", predicate=\"within\")"],"metadata":{"id":"8cx3_eeuyFSJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Eliminamos algunas columnas que no nos interesan para el estudio y cambiamos el nombre de otras para facilitarnos el trabajo más adelante. Por último, visualizamos los datos."],"metadata":{"id":"DBvbxrpr0Ani"}},{"cell_type":"code","source":["# Eliminar las columnas innecesarias\n","columnas_a_eliminar = ['NOMBRE', 'DISTRI_MT', 'FCH_ALTA', 'FCH_BAJA', 'OBSERVACIO', 'ACUERDO', 'COD_DIS', 'COD_DIS_TX', 'index_right', 'Shape_Leng', 'Shape_Area']\n","gdf_multas = gdf_multas.drop(columns=columnas_a_eliminar, errors='ignore')\n","\n","# Cambiar el nombre de la columnas de distritos y coordenadas\n","gdf_multas = gdf_multas.rename(columns={'DISTRI_MAY': 'DISTRITO'})\n","gdf_multas = gdf_multas.rename(columns={'COORDENADA-X': 'LONGITUD'})\n","gdf_multas = gdf_multas.rename(columns={'COORDENADA-Y': 'LATITUD'})\n","\n","# Cambiar el nombre de la columna 'DISTRI_MAY' a 'DISTRITO' en distritos para que sea igual en ambos casos\n","distritos = distritos.rename(columns={'DISTRI_MAY': 'DISTRITO'})\n","\n","gdf_multas.info()\n","gdf_multas.head()\n","distritos.info()\n","distritos.head()"],"metadata":{"id":"IxKXEDSzyRXx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. RESULTADOS"],"metadata":{"id":"9gmmC0rb3xVP"}},{"cell_type":"markdown","source":["En este notebook realizamos un ESDA a partir de unos datos que fueron explorados previamente en un EDA. En ese EDA se observó que el número de delitos no guardaba una relación estadísticamente significativa con variables como el área o la población. Por eso las variables del número de delitos se estudian en este ESDA sin relacionarlar con el área y la población. Si quiere acceder al EDA previo puede verlo [aquí.](https://github.com/RoberRodero/Delitos-Madrid)"],"metadata":{"id":"GQLcoDy2jnAZ"}},{"cell_type":"markdown","source":["Dentro de este ESDA los apartados de autocorrelación global y local, clusterización, regionalización y uso de algoritmos de clasificación se realizarán a partir de los datos explorados en el EDA anterior mientras que el análisis de patrones de puntos se realizará a partir de los datos de multas."],"metadata":{"id":"eYPNolTGpt-d"}},{"cell_type":"markdown","metadata":{"id":"Hc1ncjniy4Ss"},"source":["Para comenzar el análisis de autocorrelación espacial calculamos la matriz de pesos. Como los distritos aparecen repetidos para cada fecha y su distribución espacial no cambia con el tiempo solo se calculan estos pesos una vez. En el resultado que mostramos podemos ver cuantos distritos tiene como vecino inmediato cada uno de los distritos de la ciudad de Madrid."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGX77xxYdTqh"},"outputs":[],"source":["# Eliminar duplicados basados en la columna de 'DISTRITOS'\n","df_union_unique = df_union.drop_duplicates(subset='DISTRITOS')\n","\n","# Calcular la matriz de pesos con los distritos únicos\n","w = weights.Queen.from_dataframe(df_union_unique, ids=\"DISTRITOS\")\n","\n","# Ver los pesos\n","print(w.weights)"]},{"cell_type":"markdown","metadata":{"id":"445Y3A7-zLHL"},"source":["Por ejemplo, aquí podemos ver los distritos que son vecinos del distrito de Latina."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nyPXCdRvj764"},"outputs":[],"source":["w['LATINA']"]},{"cell_type":"markdown","metadata":{"id":"XR2YUtZPzZ_L"},"source":["Una vez calculada la matriz de pesos, normalizamos los valores ya que esto mejora los resultados de los cálculos que realizaremos posteriormente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qm6NJAnBlheo"},"outputs":[],"source":["# Estandarizar la matriz de pesos\n","w.transform = 'R'"]},{"cell_type":"markdown","metadata":{"id":"chGLi9Gh0pbL"},"source":["A continuacuón se puede ver como han cambiado los valores de los pesos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sH3IlE820m9s"},"outputs":[],"source":["w['LATINA']"]},{"cell_type":"markdown","metadata":{"id":"aT42IQr9zXMr"},"source":["Después, mostramos el nombre de los distristos vecinos de cada distrito."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGRPXvzcvVoc"},"outputs":[],"source":["# Verifica los vecinos de cada distrito en la matriz de pesos\n","print(w.neighbors)"]},{"cell_type":"markdown","metadata":{"id":"Fz-QCkJ_1_Nl"},"source":["Ahora que tenemos la matriz de pesos, podemos representar de manera gráfica la conectividad entre los distritos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNHpi-M-nYU-"},"outputs":[],"source":["plot_spatial_weights(w, df_union_unique, indexed_on=\"DISTRITOS\")"]},{"cell_type":"markdown","metadata":{"id":"3oJ-j8gX4vKF"},"source":["Como en nuestra base de datos contamos con información sobre varios tipos de delitos en diferentes fechas, calculamos los pesos para cada tipo de delito y fecha para poder analizar la autocorrelación espacial de cualquiera de ellos en cualquier momento. También calculamos los valores de la desviación estándar de los delitos y de la desviación estándar de los pesos de los delitos. Estas desviaciones estándar se calculan para que la magnitud de los campos no afecte al cálculo de la autocorrelación espacial. A continuación mostramos los resultados de los pesos según la fecha y el delito para cada distrito para comprobar que el resultado obtenido es coherente."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxOKiokxNzq0","collapsed":true},"outputs":[],"source":["# Lista de delitos a procesar\n","delitos = [\n","    'RELACIONADAS CON LAS PERSONAS',\n","    'RELACIONADAS CON EL PATRIMONIO',\n","    'POR TENENCIA DE ARMAS',\n","    'POR TENENCIA DE DROGAS',\n","    'POR CONSUMO DE DROGAS',\n","    'PROPIEDAD INTELECTUAL E INDUSTRIAL',\n","    'INFRACCIONES ALIMENTARIAS',\n","    'INSPECCIONES Y ACTUACIONES',\n","    'CON HERIDOS',\n","    'SIN HERIDOS',\n","    'ADULTOS',\n","    'MENORES'\n","]\n","\n","# Iterar sobre cada fecha única\n","for fecha in df_union['Fecha'].unique():\n","    # Filtrar los datos para esa fecha\n","    df_fecha = df_union[df_union['Fecha'] == fecha].copy()  # Usamos .copy() para evitar el SettingWithCopyWarning\n","\n","    # Iterar sobre cada campo en la lista de delitos\n","    for delito in delitos:\n","        # 1. Calcular la desviación estándar normalizada para el campo\n","        df_fecha[f'{delito}_std'] = (df_fecha[delito] - df_fecha[delito].mean()) / df_fecha[delito].std()\n","\n","        # 2. Aplicar el desfase espacial (lag espacial) sobre el campo original\n","        df_fecha[f'w_{delito}'] = weights.lag_spatial(w, df_fecha[delito].values)\n","\n","        # 3. Aplicar el desfase espacial (lag espacial) sobre la desviación estándar\n","        df_fecha[f'w_{delito}_std'] = weights.lag_spatial(w, df_fecha[f'{delito}_std'].values)\n","\n","        # 4. Usar .loc para actualizar el DataFrame original con las columnas calculadas\n","        df_union.loc[df_union['Fecha'] == fecha, f'{delito}_std'] = df_fecha[f'{delito}_std']\n","        df_union.loc[df_union['Fecha'] == fecha, f'w_{delito}'] = df_fecha[f'w_{delito}']\n","        df_union.loc[df_union['Fecha'] == fecha, f'w_{delito}_std'] = df_fecha[f'w_{delito}_std']\n","\n","# Ver los resultados\n","print(df_union[['Fecha', 'DISTRITOS'] + [f'w_{delito}' for delito in delitos] + [f'w_{delito}_std' for delito in delitos]])"]},{"cell_type":"markdown","metadata":{"id":"0aSW3DPt5X4m"},"source":["Después generamos una gráfica en la que mostramos la desviación estándar de cada delito frente a la desviación estandar de los pesos de cada delito. Esta gráfica se divide en cuatro cuadrantes y en función de en que cuadrante se situe cada dato se indica la relación que tiene con los datos vecinos, si se situa en el cuadrante de arriba a la izquierda quiere decir que es un valor bajo rodeado de valores altos, si se situa en el cuadrante de arriba a la derecha es un valor alto rodeado de valores altos, si se situa en el cuadrante de abajo a la derecha es un valor alto rodeado de valores bajos y si se situa en el cuadrante de abajo a la izquierda es un valor bajo rodeado de valores bajos. Además también aparece un línea que indica si la autocorrelación espacial es positiva (linea creciente hacia la derecha), negativa (linea decreciente hacia la derecha) o inexistente (linea horizontal).\n","\n","Para ilustrar un ejemplo, vamos a estudiar los resultados obtenidos con el tipo de delito Relacionados con las personas para enero de 2015 (primera fecha que aparece en el selector). Se puede observar que en el caso de que exista autocorrelación espacial estadísticamente significativa en estos datos, será de tipo negativo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9xvquMDkYynx"},"outputs":[],"source":["# Formatear las fechas para mostrar solo día, mes y año\n","df_union['Fecha_formateada'] = df_union['Fecha'].dt.strftime('%d-%m-%Y')\n","\n","# Obtener las fechas únicas, ordenarlas y quitar duplicados\n","fechas_unicas = df_union['Fecha_formateada'].unique()\n","fechas_unicas = sorted(fechas_unicas)\n","\n","# Crear un desplegable para seleccionar la fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description='Fecha:',\n","    disabled=False\n",")\n","\n","# Crear un desplegable para seleccionar el delito\n","delito_selector = widgets.Dropdown(\n","    options=delitos,\n","    description='Delito:',\n","    disabled=False\n",")\n","\n","# Función para actualizar el gráfico y calcular el índice de Moran\n","def actualizar_grafico(fecha, delito):\n","    # Filtrar los datos solo para la fecha seleccionada\n","    df_fecha = df_union[df_union['Fecha_formateada'] == fecha].copy()  # Usamos .copy() para evitar el SettingWithCopyWarning\n","\n","    # Calcular la desviación estándar normalizada para el delito seleccionado solo para esa fecha\n","    df_fecha[f'{delito}_std'] = (df_fecha[delito] - df_fecha[delito].mean()) / df_fecha[delito].std()\n","\n","    # Crear la figura y el eje para el gráfico\n","    f, ax = plt.subplots(1, figsize=(9, 9))\n","\n","    # Graficar los datos\n","    sns.regplot(x=f'{delito}_std', y=f'w_{delito}_std', data=df_fecha, ci=None, ax=ax)\n","\n","    # Añadir líneas verticales y horizontales\n","    ax.axvline(0, c='k', alpha=0.5)\n","    ax.axhline(0, c='k', alpha=0.5)\n","\n","    # Etiquetas de las regiones (HH, HL, LH, LL)\n","    texts = []\n","    texts.append(ax.text(2, 0.8, \"HH\", fontsize=25))\n","    texts.append(ax.text(2, -0.5, \"HL\", fontsize=25))\n","    texts.append(ax.text(-1, 0.5, \"LH\", fontsize=25))\n","    texts.append(ax.text(-1, -0.5, \"LL\", fontsize=25))\n","\n","    # Ajustar las posiciones de las etiquetas para evitar que se solapen con puntos\n","    adjust_text(texts, ax=ax)\n","\n","    # Mostrar el gráfico\n","    plt.title(f'Gráfico de {delito} con fecha {delito}')\n","    plt.show()\n","\n","# Mostrar la interacción entre widgets y gráfico\n","widgets.interactive(actualizar_grafico, fecha=fecha_selector, delito=delito_selector)\n"]},{"cell_type":"markdown","metadata":{"id":"TG8A78I7DpL5"},"source":["Aparte de un gráfico como el anterior, también generamos el valor del índice de Moran. Este índice indica si existe autocorrelación espacial global en los datos que estemos estudiando. Valores cercanos a 1 indican que la autocorrelación espacial es positiva, valores cercanos a -1 indican que la autocorrelación espacial es negativa y valores cercanos a 0 indican que no existe autocorrelación espacial. También se muestra el p-valor, que nos dice si el patrón espacial observado es producto del azar (p-valor > 0,05) o si realmente existe una autocorrelación espacial significativa (p-valor < 0,05).\n","\n","Continuando con el ejemplo que estamos explicando, podemos observar que la autocorrelación espacial negativa no es estadísticamente significativa.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLjq9rqaSjNy"},"outputs":[],"source":["# Crear un desplegable para seleccionar la fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description='Fecha:',\n","    disabled=False\n",")\n","\n","# Crear un desplegable para seleccionar el delito\n","delito_selector = widgets.Dropdown(\n","    options=delitos,\n","    description='Delito:',\n","    disabled=False\n",")\n","\n","# Función para actualizar el gráfico y calcular el índice de Moran\n","def actualizar_grafico(fecha, delito):\n","    # Filtrar los datos para la fecha seleccionada\n","    df_fecha = df_union[df_union['Fecha_formateada'] == fecha].copy()  # Usamos .copy() para evitar el SettingWithCopyWarning\n","\n","    # Calcular el índice de Moran para el campo seleccionado\n","    moran = esda.Moran(df_fecha[delito], w)\n","\n","    # Mostrar el índice de Moran\n","    print(f'Índice de Moran para el campo \"{delito}\" en la fecha {fecha}:')\n","    print(f'Moran I: {moran.I}')\n","    print(f'P-valor: {moran.p_sim}')\n","\n","    plot_moran(moran)\n","\n","# Mostrar los widgets y actualizar el gráfico en función de la selección\n","widgets.interactive(actualizar_grafico, fecha=fecha_selector, delito=delito_selector)"]},{"cell_type":"markdown","metadata":{"id":"SClvSdATHrSj"},"source":["Hasta ahora solo hemos estudiado la autocorrelación espacial global, pero también se puede estudiar la autocorrelación espacial local. Para analizar si existe autocorrelación local o no y de que tipo es hay que calcular los valores LISA. Lo calculamos para todos los delitos y todas la fechas asignando cada distrito a un cuadrante (los de las gráficas de autocorrelación espacial global) y si es estadísticamente significativo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yR3Br3W2d7Ye"},"outputs":[],"source":["# Iterar sobre cada fecha única\n","for fecha in df_union['Fecha'].unique():\n","    # Filtrar los datos para esa fecha\n","    df_fecha = df_union[df_union['Fecha'] == fecha].copy()\n","\n","    # Iterar sobre cada delito en la lista de delitos\n","    for delito in delitos:\n","        # Calcular el Moran Local para el delito seleccionado\n","        lisa = esda.Moran_Local(df_fecha[delito], w)\n","\n","        # Añadir una nueva columna 'significant' que será True si p-valor es menor a 0.05\n","        df_fecha['significant'] = lisa.p_sim < 0.05\n","\n","        # Añadir una nueva columna 'quadrant' con los cuadrantes\n","        df_fecha['quadrant'] = lisa.q\n","\n","        # Asignar los valores de 'significant' y 'quadrant' al DataFrame original (df_union) usando .loc\n","        df_union.loc[df_union['Fecha'] == fecha, f'{delito}_significant'] = df_fecha['significant']\n","        df_union.loc[df_union['Fecha'] == fecha, f'{delito}_quadrant'] = df_fecha['quadrant']\n","\n","# Verificar los resultados\n","print(df_union[['Fecha', 'DISTRITOS'] + [f'{delito}_significant' for delito in delitos] + [f'{delito}_quadrant' for delito in delitos]])\n"]},{"cell_type":"markdown","metadata":{"id":"XwVa8M_RNNrl"},"source":["Una vez contamos con los datos LISA podemos representarlo gráficamente. En este tipo de gráficos podemos ver los distritos representados según el cuadrante en el que han sido incluidos. Hay varias opciones:\n","\n","Que los distritos con valores altos se encuentren cerca entre sí, que los distritos con valores bajos se encuentren cerca entre sí, que distritos con valores altos se encuentran cerca de distritos con valores bajos o que distritos con valores bajos se encuentren cerca de distritos con valores altos.\n","\n"," Para el ejemplo que teníamos en la autocorrelación global, podemos ver como en algunos ditritos existe autocorrelación local, de los tipos alto-alto y bajo-alto. Este resultado podría dar lugar a un estudio más profundo acerca de la causa de esta autocorrelación local. Además, al tener datos para muchas fechas podríamos comparar entre distintos momentos en el tiempo, lo que ayudaría a encontrar las causas de este fenómeno."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bTEaGYkhFS_"},"outputs":[],"source":["# Desactivar los warnings\n","warnings.simplefilter('ignore')\n","\n","# Crear un desplegable para seleccionar la fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description='Fecha:',\n","    disabled=False\n",")\n","\n","# Crear un desplegable para seleccionar el campo\n","delito_selector = widgets.Dropdown(\n","    options=delitos,\n","    description='Delito:',\n","    disabled=False\n",")\n","\n","# Función para actualizar el gráfico y calcular el índice de Moran\n","def actualizar_grafico(fecha, delito):\n","    # Filtrar los datos solo para la fecha seleccionada\n","    df_fecha = df_union[df_union['Fecha_formateada'] == fecha].copy()\n","\n","    # Crear el gráfico\n","    f, ax = plt.subplots(1, figsize=(9, 9))\n","\n","    # Mostrar los grupos no significativos\n","    ns = df_fecha.loc[df_fecha[f'{delito}_significant'] == False, 'geometry']\n","    ns.plot(ax=ax, color='k', label='No significativo')\n","\n","    # Mostrar los grupos HH\n","    hh = df_fecha.loc[(df_fecha[f'{delito}_quadrant'] == 1) & (df_fecha[f'{delito}_significant'] == True), 'geometry']\n","    hh.plot(ax=ax, color='red', label='Alto-Alto')\n","\n","    # Mostrar los grupos LL\n","    ll = df_fecha.loc[(df_fecha[f'{delito}_quadrant'] == 3) & (df_fecha[f'{delito}_significant'] == True), 'geometry']\n","    ll.plot(ax=ax, color='blue', label='Bajo-Bajo')\n","\n","    # Mostrar los grupos LH\n","    lh = df_fecha.loc[(df_fecha[f'{delito}_quadrant'] == 2) & (df_fecha[f'{delito}_significant'] == True), 'geometry']\n","    lh.plot(ax=ax, color='#83cef4', label='Bajo-Alto')\n","\n","    # Mostrar los grupos HL\n","    hl = df_fecha.loc[(df_fecha[f'{delito}_quadrant'] == 4) & (df_fecha[f'{delito}_significant'] == True), 'geometry']\n","    hl.plot(ax=ax, color='#e59696', label='Alto-Bajo')\n","\n","    # Agregar leyenda\n","    legend_patches = [\n","        mpatches.Patch(color='red', label='Alto-Alto'),\n","        mpatches.Patch(color='blue', label='Bajo-Bajo'),\n","        mpatches.Patch(color='#83cef4', label='Bajo-Alto'),\n","        mpatches.Patch(color='#e59696', label='Alto-Bajo'),\n","        mpatches.Patch(color='k', label='No significativo')\n","    ]\n","    ax.legend(handles=legend_patches, loc='lower right')\n","\n","    # Estilo y visualización\n","    f.suptitle(f'LISA de {delito} en {fecha}', size=16)\n","    f.set_facecolor('0.75')\n","    ax.set_axis_off()\n","    plt.show()\n","\n","# Mostrar la interacción entre widgets y gráfico\n","widgets.interactive(actualizar_grafico, fecha=fecha_selector, delito=delito_selector)\n"]},{"cell_type":"markdown","metadata":{"id":"nZcpobUENXxc"},"source":["También podemos representarlo junto al diagrama de dispersión de moran y los valores del delito por distrito en una fecha determinada para tener una visión más completa de los datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ms6JQ_F5pafc"},"outputs":[],"source":["# Crear un desplegable para seleccionar la fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description='Fecha:',\n","    disabled=False\n",")\n","\n","# Crear un desplegable para seleccionar el delito\n","campo_selector = widgets.Dropdown(\n","    options=delitos,\n","    description='delito:',\n","    disabled=False\n",")\n","\n","# Función para actualizar el gráfico y calcular el índice de Moran\n","def actualizar_grafico(fecha, delito):\n","    # Filtrar los datos solo para la fecha seleccionada\n","    df_fecha = df_union[df_union['Fecha_formateada'] == fecha].copy()  # Usamos .copy() para evitar el SettingWithCopyWarning\n","\n","    lisa2 = esda.Moran_Local(df_fecha[delito], w)\n","\n","    plot_local_autocorrelation(lisa2, df_fecha, df_fecha[delito])\n","\n","# Mostrar la interacción entre widgets y gráfico\n","widgets.interactive(actualizar_grafico, fecha=fecha_selector, delito=delito_selector)"]},{"cell_type":"markdown","metadata":{"id":"qJh3vbiwb6GS"},"source":["# Clustering y regionalización.\n"]},{"cell_type":"markdown","metadata":{"id":"C1GVGUBz0jXO"},"source":["A continuación, para seguir con el ESDA, en este apartado vamos a agrupar los distritos en clusters y también a regionalizar y comparar la diferencia en las agrupaciones generadas en función de los delitos y las divisiones administrativas reales. Como tenemos datos para cada mes durante una década, permitimos al usuario que elija para que periodo de tiempo desea ver estas agrupaciones."]},{"cell_type":"markdown","metadata":{"id":"4IJq3XHi1bxW"},"source":["Para ello en primer lugar vamos a hacer un ejemplo para 5 clusters. Mas adelante veremos un par de métodos para seleccionar el número óptimo de clusters para los datos de estudio pero realizar un primer ejemplo nos parece interesante para una primera visualización de los resultados.\n","\n","Como resultado del siguiente código podemos ver a que cluster se ha asignado cada distrito para cada fecha."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUf6BIJompMP"},"outputs":[],"source":["# Definir el modelo KMeans, determinando el número de clusters y una seed\n","kmeans5 = KMeans(n_clusters=5, random_state=12345, n_init=10)\n","\n","# Iterar sobre cada fecha única\n","for fecha in df_union['Fecha'].unique():\n","    # Filtrar los datos para esa fecha\n","    df_fecha = df_union[df_union['Fecha'] == fecha].copy()\n","\n","    # Ejecutar el algoritmo de clustering\n","    k5clust = kmeans5.fit(df_fecha[delitos])\n","\n","    # Guardar los clusters en la columna 'k5clust' en df_union\n","    df_union.loc[df_union['Fecha'] == fecha, 'k5clust'] = k5clust.labels_\n","\n","# Ver los primeros resultados\n","print(df_union[['Fecha', 'k5clust']].head())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Dg75WtLm2Sl9"},"source":["Una vez asignamos cada distrito a una grupo o cluster podemos representar gráficamente el resutado. Podemos ver que como los datos de delitos son diferentes para cada fecha, las agrupaciones van cambiando dependiendo del momento en el que estudiemos los grupos.\n","\n","Tomando como ejemplo la misma fecha que al estudiar la autocorrelación local y global, podemos ver como existe un gran grupo en el norte y Este de la ciudad y el resto de grupos se dividen entre los distritos del centro, sur y oeste."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jk-bpDuypLnP"},"outputs":[],"source":["# Obtener fechas únicas, ordenarlas y formatearlas como \"DD/MM/AAAA\"\n","fechas_unicas = sorted(df_union['Fecha'].dt.strftime('%Y/%m/%d').unique())\n","\n","# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","# Función para actualizar el mapa según la fecha seleccionada\n","def actualizar_mapa(fecha_str):\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Limpiar la figura anterior\n","    plt.clf()\n","\n","    # Crear nueva figura\n","    f, ax = plt.subplots(1, figsize=(18, 9))\n","\n","    # Graficar mapa\n","    df_filtrado.plot(\n","        column='k5clust', categorical=True, legend=True, linewidth=0, ax=ax\n","    )\n","\n","    # Quitar ejes y añadir título\n","    ax.set_axis_off()\n","    plt.title(f'Clasificación geodemográfica por delitos - {fecha_str}')\n","\n","    # Mostrar el mapa\n","    plt.show()\n","\n","# Usar interact para actualizar dinámicamente\n","widgets.interactive(actualizar_mapa, fecha_str=fecha_selector)\n"]},{"cell_type":"markdown","metadata":{"id":"Cwhz7YsF_fUG"},"source":["A continuación mostramos el mismo resultado en forma de tabla, permitiendo al usuario seleccionar que fecha quiere ver."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9s1si_Q5tlaM"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","# Crear un widget de salida para mostrar los resultados\n","output = widgets.Output()\n","\n","# Función para calcular el tamaño de los clusters de KMeans por fecha seleccionada\n","def calcular_tamano_clusters(fecha_str):\n","    # Limpiar la salida anterior\n","    with output:\n","        clear_output(wait=True)\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Calcular el tamaño de los clusters\n","    kmeans5sizes = df_filtrado.groupby('k5clust').size()\n","\n","    # Mostrar el resultado\n","    with output:\n","        print(f\"Tamaño de los clusters para la fecha: {fecha_str}\")\n","        display(kmeans5sizes)\n","\n","# Usar interactive_output para evitar la firma de la función\n","widgets.interactive_output(calcular_tamano_clusters, {'fecha_str': fecha_selector})\n","display(fecha_selector, output)"]},{"cell_type":"markdown","metadata":{"id":"e6OMvC2J_5M9"},"source":["También mostramos estos resultados como gráfica de barras, permitiendo una vez mas al usuario seleccionar que fecha quiere ver."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lxCZI-mwZrZ"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","# Función para actualizar el mapa según la fecha seleccionada\n","def barras(fecha_str):\n","  # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Calcular el tamaño de los clusters\n","    kmeans5sizes = df_filtrado.groupby('k5clust').size()\n","\n","    bar_kmeans5 = kmeans5sizes.plot.bar()\n","\n","    # Mostrar el gráfico actualizado\n","    plt.show()\n","\n","# Usar interact para actualizar dinámicamente\n","widgets.interactive(barras, fecha_str=fecha_selector)"]},{"cell_type":"markdown","metadata":{"id":"pbn_R4pBAtD2"},"source":["Para terminar con el ejemplo de 5 clusters, mostramos el número de delitos medios cometidos en cada clúster. Ya a partir de este resultado podemos ver como probablemente tomar 5 clústers no es óptimo ya que en algunos de ellos el número medio de delitos es muy similar. Si lo comprobamos para varias fechas podemos ver como este problema se repite."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEfHDGb-BEHw"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","# Crear un widget de salida para mostrar los resultados\n","output = widgets.Output()\n","\n","# Función para calcular el tamaño de los clusters de KMeans por fecha seleccionada\n","def tabla(fecha_str):\n","    # Limpiar la salida anterior\n","    with output:\n","        clear_output(wait=True)\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Calcular el número de delitos por tipo de los clusters\n","    k5meanss = df_filtrado.groupby('k5clust')[delitos].mean()\n","\n","    # Mostrar el resultado\n","    with output:\n","        print(f\"Tamaño de los clusters para la fecha: {fecha_str}\")\n","        display(k5meanss.T)\n","\n","# Usar interactive_output para evitar la firma de la función\n","widgets.interactive_output(tabla, {'fecha_str': fecha_selector})\n","display(fecha_selector, output)"]},{"cell_type":"markdown","metadata":{"id":"rSs2jPNEDQlR"},"source":["Para continuar con la clusterización vamos a utilizar un método diferente, AgglomerativeClustering, que aparte de permitirnos agrupar en el número de cluster que deseemos (al igual que hacía Kmeans), también nos permite generar un dendograma en el que ver si el número de clúster seleccionado es idóneo o no. Para comenzar a utilizar este ejemplo hemos decidido hacerlo en esta ocasion con 8 clusters como punto de partido, generando el mapa que se ve a continuación.\n","\n","Si comparamos con el ejemplo utilizando 5 clusters podemos ver las diferencias que genera utilizar un número diferente de clusters para hacer la agrupación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLPnhi2rG_sC"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","# Función para actualizar el mapa según la fecha seleccionada\n","def agregar(fecha_str):\n","  # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    s_agg13 = AgglomerativeClustering(n_clusters=8, connectivity=w.sparse)\n","\n","    # Ejecutar el algoritmo de clustering\n","    s_agg13clust = s_agg13.fit(df_filtrado[delitos])\n","    df_filtrado['sagg13clust'] = s_agg13clust.labels_\n","\n","    # Crear gráfico\n","    f, ax = plt.subplots(1, figsize=(9, 9))\n","\n","    # Mostrar los valores\n","    df_filtrado.plot(\n","        column='sagg13clust', categorical=True, legend=True, linewidth=0, ax=ax\n","    )\n","    # Quitar los ejes\n","    ax.set_axis_off()\n","\n","    # Añadir título\n","    plt.title(f\"Tamaño de los clusters para la fecha: {fecha_str}\")\n","\n","    # Mostrar el mapa\n","    plt.show()\n","\n","# Usar interact para actualizar dinámicamente\n","widgets.interactive(agregar, fecha_str=fecha_selector)"]},{"cell_type":"markdown","metadata":{"id":"pCDO4zmkEMzY"},"source":["A continuación, generamos el dendograma para ver si hemos seleccionado un número correcto de clusters. Como podemos observar, parece que el número más idóneo independientemente de la fecha son 2 clústers (en algunos casos 3). La fecha que estamos tomando como ejemplo no es una excepción y aparentemente tiene un número ideal de 2 clusters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EqQAtaXKbwj"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","# Función para actualizar el mapa según la fecha seleccionada\n","def dendro(fecha_str):\n","  # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Filtrar por delitos\n","    data = df_filtrado[delitos].values\n","\n","    # Calcular la matriz de enlace usando el método 'ward'\n","    Z = linkage(data, method='ward')\n","\n","    # Crear el dendrograma truncado mostrando sólo los últimos 10 clusters\n","    plt.figure(figsize=(12, 6))\n","    dendrogram(Z, truncate_mode='lastp', p=13, leaf_rotation=90, leaf_font_size=10)\n","    plt.title(\"Dendrograma (truncado)\")\n","    plt.xlabel(\"Índice del cluster o muestra\")\n","    plt.ylabel(\"Distancia\")\n","    plt.show()\n","\n","# Usar interact para actualizar dinámicamente\n","widgets.interactive(dendro, fecha_str=fecha_selector)"]},{"cell_type":"markdown","metadata":{"id":"nMTWFeIEE96W"},"source":["Aparte de utilizar un dendograma, también existen otros métodos para determinar el número ideal de clústers. En primer lugar tenemos el índice de silueta, que es una medida de evaluación utilizada para determinar la calidad de un agrupamiento (clustering). Se usa para evaluar cuán bien se ha realizado el agrupamiento comparando la distancia dentro de los clusters y la distancia entre los clusters. Su valor ayuda a entender qué tan coherentes y bien separados están los grupos formados. Si valores son cercanos a 1 los puntos están bien agrupados, y los clusters son compactos y bien separados. Si el valor es cercano a 0 los puntos están en la frontera entre clusters, lo que indica que no están claramente asignados a uno u otro cluster. Si el valor es cercano a -1 los puntos están mal asignados, ya que deberían pertenecer a otro cluster.\n","\n","Con el siguiente código se puede seleccionar el número óptimo de casos según el índice de silueta para cada fecha, que en la mayoría de los casos es 2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0SCHZTCNW0-"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","def indice_silueta_optimo(fecha_str):\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Convertir los datos a un array NumPy\n","    data = df_filtrado[delitos].values\n","\n","    mejor_silueta = -1  # Valor inicial para el índice de silueta\n","    mejor_clusters = 2  # Número inicial de clusters\n","\n","    # Probar varios números de clusters, por ejemplo, de 2 a 10\n","    for n_clusters in range(2, 11):\n","        model = AgglomerativeClustering(n_clusters=n_clusters)\n","        labels = model.fit_predict(data)  # Obtener etiquetas de los clusters\n","        silhouette_avg = silhouette_score(data, labels)  # Calcular índice de silueta\n","\n","        print(f\"Índice de silueta para {n_clusters} clusters: {silhouette_avg:.4f}\")\n","\n","        # Si encontramos un índice de silueta mayor, actualizamos el mejor número de clusters\n","        if silhouette_avg > mejor_silueta:\n","            mejor_silueta = silhouette_avg\n","            mejor_clusters = n_clusters\n","\n","    print(f\"\\nEl mejor número de clusters es: {mejor_clusters} con un índice de silueta de {mejor_silueta:.4f}\")\n","\n","# Crear un selector de fecha\n","widgets.interactive(indice_silueta_optimo, fecha_str=fecha_selector)\n"]},{"cell_type":"markdown","metadata":{"id":"yqvCskZVIjan"},"source":["Otra forma de determinar el mejor número de clusters es el método del codo que es una técnica muy utilizada para determinar el número óptimo de clusters (k) en algoritmos de clustering. Se basa en graficar el error cuadrático dentro del cluster en funciónn de los diferentes valores de k.El gráfico generalmente muestra una disminución rápida de WCSS cuando se aumenta k al principio, y luego la disminución se hace más gradual. El \"codo\" es el punto donde esta disminución empieza a ser más lenta. El número de clusters en este punto (el \"codo\") es el número óptimo de clusters, ya que después de este punto, añadir más clusters no reduce significativamente la dispersión dentro de los clusters.\n","\n","Si observamos los resultados obtenidos mediante este método podemos ver como coincide con el indice de silueta, ya que en la mayoría de fechas el mejor numero de clusters es 2.\n","\n","Tanto en con el índice de silueta como con el método del codo el número óptimo de clusters para la fecha que tomamos como ejemplo es 2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IW4-tV7NhiX"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","def metodo_del_codo(fecha_str):\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Convertir los datos a un array NumPy\n","    data = df_filtrado[delitos].values\n","\n","    # Probar diferentes números de clusters, por ejemplo, de 1 a 10\n","    sse = []\n","    for n_clusters in range(1, 11):\n","        model = KMeans(n_clusters=n_clusters)\n","        model.fit(data)\n","        sse.append(model.inertia_)  # Guardar el SSE para cada número de clusters\n","\n","    # Graficar el método del codo\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(1, 11), sse, marker='o')\n","    plt.title('Método del Codo')\n","    plt.xlabel('Número de Clusters')\n","    plt.ylabel('SSE')\n","    plt.show()\n","\n","# Crear un selector de fecha\n","widgets.interactive(metodo_del_codo, fecha_str=fecha_selector)\n"]},{"cell_type":"markdown","metadata":{"id":"iOKI41JKKKZG"},"source":["Una vez que hemos seleccionado la manera de determinar el mejor número de clusters, lo que vamos a hacer es agrupar según ese número de clusters y disolver los distritos que pertenezcan al mismo grupo mediante la función dissolve, definida a continuación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vx3M_5RAPmVu"},"outputs":[],"source":["def dissolve(gs):\n","    '''\n","    Toma una serie de polígonos y los une en un solo polígono\n","\n","    Argumentos\n","    ---------\n","    gs        : GeoSeries\n","                Secuencia de polígonos a disolver\n","    Devuelve\n","    -------\n","    disuelto : Polígono\n","               Un único polígono que contiene todos los polígonos en `gs`\n","    '''\n","    return gs.union_all()"]},{"cell_type":"markdown","metadata":{"id":"7Qn6iFTANEBH"},"source":["A continuación se puede observar el resultado en un mapa de agrupar por el mejor número de clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPqFcszHL9t-"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","def cambio_2(fecha_str):\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Convertir los datos a un array NumPy\n","    data = df_filtrado[delitos].values\n","\n","    # Variables para determinar el mejor número de clusters (con índice de silueta)\n","    mejor_silueta = -1\n","    mejor_clusters = 2\n","\n","    # Probar varios números de clusters (por ejemplo, de 2 a 10)\n","    for n_clusters in range(2, 11):\n","        model = AgglomerativeClustering(n_clusters=n_clusters)\n","        labels = model.fit_predict(data)  # Obtener etiquetas de los clusters\n","        silhouette_avg = silhouette_score(data, labels)  # Calcular índice de silueta\n","\n","        # Actualizar el mejor número de clusters basado en el índice de silueta\n","        if silhouette_avg > mejor_silueta:\n","            mejor_silueta = silhouette_avg\n","            mejor_clusters = n_clusters\n","\n","    # Ahora usa el mejor número de clusters encontrado\n","    s_agg13 = AgglomerativeClustering(n_clusters=mejor_clusters, connectivity=w.sparse)\n","\n","    # Ejecutar el algoritmo de clustering aglomerativo\n","    s_agg13clust = s_agg13.fit(df_filtrado[delitos])\n","    df_filtrado['sagg13clust'] = s_agg13clust.labels_\n","\n","    # Disolver las geometrías basadas en los clusters\n","    distritos_delitos = gpd.GeoSeries(\n","        df_filtrado.groupby(df_filtrado['sagg13clust']).apply(dissolve),\n","        crs=df_filtrado.crs\n","    )\n","\n","    # Configurar la figura y el eje para la visualización\n","    f, ax = plt.subplots(1, figsize=(6, 6))\n","\n","    # Dibujar el mapa base de OpenStreetMap con contextily\n","    distritos_delitos = distritos_delitos.to_crs(epsg=3857)  # Cambiar a coordenadas web Mercator\n","    distritos_delitos.plot(ax=ax, linewidth=0.5, facecolor='white', edgecolor='k', alpha=0.8)  # alpha para opacidad\n","\n","    # Añadir el mapa base\n","    cx.add_basemap(ax, crs=distritos_delitos.crs.to_string(), source=cx.providers.OpenStreetMap.Mapnik)\n","\n","    # Eliminar el eje\n","    ax.set_axis_off()\n","\n","    # Añadir el título\n","    plt.title(f'Distritos basados en delitos para {mejor_clusters} clusters')\n","    plt.show()\n","\n","# Crear un selector de fecha\n","widgets.interactive(cambio_2, fecha_str=fecha_selector)"]},{"cell_type":"markdown","metadata":{"id":"MTni_TGrOUY-"},"source":["Por último, podemos ver la diferencia entre la distribución de los distritos real (en azul) y la generada según los delitos (naranja). Para la mayoría de las fechas el resultado es el mismo, generando un grupo para el distrito centro y otro para el resto de los distritos. En algunas fechas, como noviembre de 2021 se generan tres grupos según delito, pero hay algo en común y es que en todos los casos parece haber una diferencia clara entre el centro de la ciudad y el resto de los distritos. Para saber las causas de esta distribución de delitos podría ser interesante incluir más variables, como centros de ocio, números de de comisarías o patrullas de policía, afluencia de turistas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-kkqSXGVjmQ"},"outputs":[],"source":["# Crear un widget de selección de fecha\n","fecha_selector = widgets.Dropdown(\n","    options=fechas_unicas,\n","    description=\"Fecha:\",\n","    style={'description_width': 'initial'}\n",")\n","\n","def cambio_3(fecha_str):\n","    # Convertir la fecha seleccionada de string a datetime\n","    fecha = pd.to_datetime(fecha_str, format='%Y/%m/%d')\n","\n","    # Filtrar el DataFrame por la fecha seleccionada\n","    df_filtrado = df_union[df_union['Fecha'] == fecha]\n","\n","    # Convertir los datos a un array NumPy\n","    data = df_filtrado[delitos].values\n","\n","    # Variables para determinar el mejor número de clusters (con índice de silueta)\n","    mejor_silueta = -1\n","    mejor_clusters = 2\n","\n","    # Probar varios números de clusters (por ejemplo, de 2 a 10)\n","    for n_clusters in range(2, 11):\n","        model = AgglomerativeClustering(n_clusters=n_clusters)\n","        labels = model.fit_predict(data)  # Obtener etiquetas de los clusters\n","        silhouette_avg = silhouette_score(data, labels)  # Calcular índice de silueta\n","\n","        # Actualizar el mejor número de clusters basado en el índice de silueta\n","        if silhouette_avg > mejor_silueta:\n","            mejor_silueta = silhouette_avg\n","            mejor_clusters = n_clusters\n","\n","    # Ahora usa el mejor número de clusters encontrado\n","    s_agg13 = AgglomerativeClustering(n_clusters=mejor_clusters, connectivity=w.sparse)\n","\n","    # Ejecutar el algoritmo de clustering aglomerativo\n","    s_agg13clust = s_agg13.fit(df_filtrado[delitos])\n","    df_filtrado['sagg13clust'] = s_agg13clust.labels_\n","\n","    # Disolver las geometrías basadas en los clusters\n","    distritos_delitos = gpd.GeoSeries(\n","        df_filtrado.groupby(df_filtrado['sagg13clust']).apply(dissolve),\n","        crs=df_filtrado.crs\n","    )\n","    # Crear la imagen\n","    f, ax = plt.subplots(1, figsize=(12, 12))\n","    f.set_facecolor(\"w\")\n","\n","    # Añadir los distritos\n","    df_filtrado.to_crs(\n","        epsg=25830\n","    ).plot(\n","        ax=ax,\n","        facecolor=\"none\",\n","        edgecolor=\"xkcd:salmon\",\n","        linewidth=2\n","    )\n","\n","    # Añadir la regionalización\n","    distritos_delitos.to_crs(\n","        epsg=25830\n","    ).plot(\n","        ax=ax,\n","        facecolor=\"none\",\n","        edgecolor=\"xkcd:blue\",\n","        linewidth=1.5\n","    )\n","\n","    # Añadir el mapa base\n","    cx.add_basemap(\n","        ax,\n","        crs=\"EPSG:25830\",\n","        source=cx.providers.CartoDB.PositronNoLabels\n","    )\n","\n","    # Quitar ejes\n","    ax.set_axis_off()\n","\n","    # Añadir el título\n","    plt.title(f'Distritos reales y regionalización')\n","\n","    # Mostrar la imagen\n","    plt.show()\n","\n","# Crear un selector de fecha\n","widgets.interactive(cambio_3, fecha_str=fecha_selector)"]},{"cell_type":"markdown","metadata":{"id":"IY7UdGltx8FA"},"source":["**ANÁLISIS DE PATRONES DE PUNTOS APLICADO A MULTAS DE TRÁFICO EN MADRID**"]},{"cell_type":"markdown","metadata":{"id":"EH-MSTHj_2BZ"},"source":["**Visualización de un patrón de puntos**"]},{"cell_type":"markdown","source":["Como estos datos no se exploraron en el EDA anterior, realizamos una inspección visual de los mismos a través de varios mapas."],"metadata":{"id":"fxsit8qc3ylc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4RNaJM7_Uer"},"outputs":[],"source":["# Plotear puntos\n","gdf_multas.plot.scatter(\"LONGITUD\", \"LATITUD\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhiNkMPyACX5"},"outputs":[],"source":["# Plotear puntos\n","ax = gdf_multas.plot.scatter(\n","    \"LONGITUD\",\n","    \"LATITUD\",\n","    s=0.25,\n","    c=\"xkcd:bright yellow\",\n","    alpha=0.5,\n","    figsize=(9, 9)\n",")\n","\n","# Eliminar ejes\n","ax.set_axis_off()\n","\n","# Añadir mapa base con tonalidad oscura\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatter\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nS9hzSQNFSMh"},"outputs":[],"source":["# Plotear con la distribución de puntos por latitud y longitud\n","joint_axes = sns.jointplot(\n","    x='LONGITUD', y='LATITUD', data=gdf_multas, s=1\n",")\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    joint_axes.ax_joint,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.PositronNoLabels\n",")"]},{"cell_type":"markdown","metadata":{"id":"HGg-DIBLS_0i"},"source":["**Unión de puntos en polígonos**"]},{"cell_type":"markdown","source":["En este punto, se propone visualizar los datos puntuales en forma de polígonos, convirtiéndolos para poder mapear las multas en forma de coropletas. En primer lugar, se representarán como rejillas irregulares con la delimitiación de los distritos de Madrid."],"metadata":{"id":"gUvQqLiumMgb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtFSAHd-pBEt"},"outputs":[],"source":["# Convertir los distritos a 25830 para visualizarlo correctamente\n","distritos = distritos.to_crs(epsg=25830)\n","\n","# Plotear puntos\n","ax = gdf_multas.plot.scatter(\n","    \"LONGITUD\",\n","    \"LATITUD\",\n","    s=0.25,\n","    c=\"xkcd:bright yellow\",\n","    alpha=0.5,\n","    figsize=(9, 9)\n",")\n","\n","# Añadir delimitación de distritos\n","distritos.plot(\n","    ax=ax,\n","    facecolor=\"none\",\n","    edgecolor=\"xkcd:pale lavender\"\n",")\n","\n","# Eliminar ejes\n","ax.set_axis_off()\n","\n","# Añadir mapa base con tonalidad oscura\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatter\n",")"]},{"cell_type":"markdown","source":["Ahora obtendremos cuántas multas hay en cada uno de los distritos de Madrid. Para ello agruparemos los datos por la columna \"DISTRITO\" y aplicaremos el método size para contar las multas de cada distrito, organizando los datos en la columna \"multas_zona\" de la nueva tabla \"multas_distritos\"."],"metadata":{"id":"f-Az4WJ3oGCg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpDzPDnQXd-d"},"outputs":[],"source":["# Contar multas por distritos\n","multas_distritos = gdf_multas.groupby(\"DISTRITO\").size()\n","\n","# Asignar el número de multas por distrito a la columna \"multas_zona\" y unir por distritos\n","areas = distritos.join(\n","    pd.DataFrame({\"multas_zona\": multas_distritos}),\n","    on=\"DISTRITO\"\n",")\n","\n","areas.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YEHXBBk2aA79"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(9, 9))\n","\n","# Plotear multas por distrito por el métodos de cuantiles y con transparencia\n","areas.plot(\n","    column='multas_zona',\n","    scheme='quantiles',\n","    ax=ax,\n","    legend=True,\n","    legend_kwds={\"loc\": 4},\n","    alpha=0.4\n",")\n","\n","# Eliminar los ejes\n","ax.set_axis_off()\n","\n","# Título del gráfico\n","ax.set_title(\"Multas por distritos de Madrid\")\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatterNoLabels\n",")\n","\n","# Mapear\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eXtdazmrbHA8"},"source":["**Densidad de multas por distrito**"]},{"cell_type":"markdown","source":["También resulta útil conocer la densidad de multas por área, en este caso por kilómetros cuadrados. Para ello, una vez tenemos el área de cada distrito, hacemos el conteo de multas en base al área de cada distrito."],"metadata":{"id":"iWn6xK2qpqwB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M-ZhYRNWaRXN"},"outputs":[],"source":["# Obtener el área (en kilómetros cuadrados) de cada distrito\n","areas[\"area_km2\"] = areas.to_crs(epsg=25830).area * 1e-6\n","areas.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9fTA7LzbFDF"},"outputs":[],"source":["areas[\"densidad_multas\"] = areas[\"multas_zona\"] / areas[\"area_km2\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2MxhiaQbYfv"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(9, 9))\n","\n","# Plotear densidad de multas por distrito por el métodos de cuantiles y con transparencia\n","areas.plot(\n","    column='densidad_multas',\n","    scheme='quantiles',\n","    ax=ax,\n","    legend=True,\n","    legend_kwds={\"loc\": 4},\n","    alpha=0.4\n",")\n","\n","# Eliminar ejes\n","ax.set_axis_off()\n","\n","# Título\n","ax.set_title(\"Densidad de multas por km2 en los distritos de Madrid\")\n","\n","# Añadir mapa base con tonalidad oscura\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatterNoLabels\n",")\n","\n","# Mapear\n","plt.show()"]},{"cell_type":"markdown","source":["Evidentemente, los distritos con mayor densidad de multas son las áreas céntricas y más concurridas, como el distrito Centro, Chamberí y Chamartín."],"metadata":{"id":"K4ueePZ3q9ak"}},{"cell_type":"markdown","source":["También se puede convertir estos datos puntuales en forma de polígonos, pero en este caso como rejillas regulares, en forma de una cuadrícula de hexágonos, por ejemplo, lo cual tiene la ventaja de proporcionar una topología regular en la que cada polígono tiene el mismo tamaño y forma."],"metadata":{"id":"Y0CVHIdXrshe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7oLlwdTbcCHP"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(16, 12))\n","\n","# Añadir los datos puntuales de multas en forma de hexágonos\n","hb = ax.hexbin(\n","    gdf_multas[\"LONGITUD\"],\n","    gdf_multas[\"LATITUD\"],\n","    gridsize=50,\n","    alpha=0.5,\n","    edgecolor=\"none\"\n",")\n","\n","# Añadir barra de color\n","plt.colorbar(hb)\n","\n","# Eliminar ejes\n","ax.set_axis_off()\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatterNoLabels\n",")\n","\n","# Título\n","ax.set_title(\"Hex-binning de multas en Madrid\")\n","\n","# Mepear\n","plt.show()"]},{"cell_type":"markdown","source":["Gracias a este mapa podemos observar que el punto en el que mayor cantidad de multas hubo en Madrid en mayo de 2024 se ubica en un parking junto al recinto de la Caja Mágica, donde durante este mes tuvieron lugar importantes eventos como el Mutua Madrid Open de tenis o el Festival Tomavistas Madrid, que tuvieron una gran afluencia de público y por tanto dispararon la cifra de multas a su alrededor."],"metadata":{"id":"QaNUJo4etQ99"}},{"cell_type":"markdown","metadata":{"id":"JreS8Ct9cTyH"},"source":["**Estimación de la densidad de kernel**"]},{"cell_type":"markdown","source":["Para contar el número de multas en Madrid de manera continua en el espacio, emplearemos el método de estimación de densidad de kernel (KDE), en base a una muestra de 1.000 puntos aleatorios de los datos originales."],"metadata":{"id":"WCh0w1VLuzJN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tInc2tmEcWQd"},"outputs":[],"source":["# Tomar una muestra de 1.000 puntos de manera aleatoria\n","gdf_multas_sub = gdf_multas.sample(1000, random_state=12345)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RO0gJgJNck0O"},"outputs":[],"source":["sns.kdeplot(\n","    x=\"LONGITUD\",\n","    y=\"LATITUD\",\n","    data=gdf_multas_sub,\n","    n_levels=50,\n","    fill=True,\n","    cmap='BuPu'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dcjD6YQdsLP"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(12, 12))\n","\n","# Añadir el cálculo de la densidad de kernel\n","sns.kdeplot(\n","    x='LONGITUD',\n","    y='LATITUD',\n","    data=gdf_multas_sub,\n","    n_levels=50,\n","    fill=True,\n","    alpha=0.25,\n","    cmap=\"viridis\"\n",")\n","\n","# Eliminar ejes\n","ax.set_axis_off()\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.DarkMatterNoLabels\n",")\n","\n","# Título\n","ax.set_title(\"KDE de multas en Madrid\")\n","\n","# Mapear\n","plt.show()"]},{"cell_type":"markdown","source":["Gráfico KDE bivariado con contornos"],"metadata":{"id":"TfXPC4M4v5ct"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vj2Czd1Ne0Rl"},"outputs":[],"source":["joint_axes = sns.jointplot(\n","    x='LONGITUD', y='LATITUD', data=gdf_multas_sub, kind=\"kde\"\n",")\n","\n","cx.add_basemap(\n","    joint_axes.ax_joint,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.PositronNoLabels\n",")"]},{"cell_type":"markdown","metadata":{"id":"iA14GQBRfQSn"},"source":["**Análisis estadístico de patrones de puntos con funciones de Ripley**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkziiCSIfU6m"},"outputs":[],"source":["coordinates = gdf_multas_sub[['LONGITUD','LATITUD']].values\n","coordinates"]},{"cell_type":"markdown","metadata":{"id":"UraXtl64fmMt"},"source":["**G de Ripley**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzOe8Rdhfk6E"},"outputs":[],"source":["g_test = distance_statistics.g_test(\n","    coordinates, support=40, keep_simulations=True, n_simulations=999\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RSRx52cTgN4f"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, 2, figsize=(9, 3), gridspec_kw=dict(width_ratios=(6, 3)))\n","\n","# Graficar todas las simulaciones\n","ax[0].plot(g_test.support, g_test.simulations.T, color='k', alpha=.01)\n","\n","# Mostrar la mediana de las simulaciones\n","ax[0].plot(g_test.support, np.median(g_test.simulations, axis=0), color='cyan',\n","           label='mediana de simulaciones')\n","\n","# Graficar la función G observada del patrón\n","ax[0].plot(g_test.support, g_test.statistic, label='observado', color='red')\n","\n","# Limpiar etiquetas y ejes\n","ax[0].set_xlabel('distancia')\n","ax[0].set_ylabel('% de distancias al vecino más cercano\\nmenores')\n","ax[0].legend()\n","ax[0].set_xlim(0, 2000)\n","ax[0].set_title(r\"Función $G(d)$ de Ripley\")\n","\n","# Graficar el patrón de puntos en el segundo subgráfico\n","ax[1].scatter(*coordinates.T)\n","\n","# Limpiar etiquetas y ejes en el segundo subgráfico\n","ax[1].set_xticks([])\n","ax[1].set_yticks([])\n","ax[1].set_xticklabels([])\n","ax[1].set_yticklabels([])\n","ax[1].set_title('Patrón de puntos')\n","f.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","source":["En el gráfico se observa que la función observada aumenta de manera muy rápida en comparación con los patrones simulados, por lo que el patrón observado sí está agrupado, ya que sus puntos están más cerca entre sí de lo que sería esperado en una distribución aleatoria."],"metadata":{"id":"S8XcATZExdos"}},{"cell_type":"markdown","metadata":{"id":"_WTIKgcRgseF"},"source":["**F de Ripley**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuMslIZggrbG"},"outputs":[],"source":["f_test = distance_statistics.f_test(\n","    coordinates, support=40, keep_simulations=True, n_simulations=999\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEh0B33vg8ds"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, 2, figsize=(9, 3), gridspec_kw=dict(width_ratios=(6, 3)))\n","\n","# Graficar todas las simulaciones\n","ax[0].plot(f_test.support, f_test.simulations.T, color='k', alpha=.01)\n","\n","# Mostrar la mediana de las simulaciones\n","ax[0].plot(f_test.support, np.median(f_test.simulations, axis=0), color='cyan',\n","           label='mediana de simulaciones')\n","\n","# Graficar la función F observada del patrón\n","ax[0].plot(f_test.support, f_test.statistic, label='observado', color='red')\n","\n","# Limpiar etiquetas y ejes\n","ax[0].set_xlabel('distancia')\n","ax[0].set_ylabel('% de distancias menores\\nal punto más cercano en el patrón')\n","ax[0].legend()\n","ax[0].set_xlim(0, 2000)\n","ax[0].set_title(r\"Función $F(d)$ de Ripley\")\n","\n","# Graficar el patrón de puntos en el segundo subgráfico\n","ax[1].scatter(*coordinates.T)\n","\n","# Limpiar etiquetas y ejes en el segundo subgráfico\n","ax[1].set_xticks([])\n","ax[1].set_yticks([])\n","ax[1].set_xticklabels([])\n","ax[1].set_yticklabels([])\n","ax[1].set_title('Patrón de puntos')\n","f.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","source":["En este caso, la función observada aumenta más lentamente en comparación con los patrones simulados, por lo que el patrón observado sí está agrupado, ya que la cantidad de grandes áreas vacías es superior en el patrón de la simulaciones."],"metadata":{"id":"krxyrE0axU98"}},{"cell_type":"markdown","metadata":{"id":"HS8psCp_hH42"},"source":["**Agrupaciones o clusters de puntos**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfmohFU6hOrO"},"outputs":[],"source":["# Configurar el algoritmo DBSCAN\n","algorit = DBSCAN(eps=100, min_samples=50) # Mínimo 50 multas dentro de un radio de 100 metros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAdY2WMphyn0"},"outputs":[],"source":["# Ajustar el cluster a los datos de multas\n","algorit.fit(gdf_multas[[\"LONGITUD\", \"LATITUD\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICQ49aJrof2x"},"outputs":[],"source":["# Obtener las etiquetas\n","algorit.labels_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P34ygWbYoi2c"},"outputs":[],"source":["# Mostrar los primeros 5 valores\n","algorit.core_sample_indices_[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAQk5OBKok9i"},"outputs":[],"source":["# Convertir las etiquetas en un objeto Serie\n","labels = pd.Series(algorit.labels_, index=gdf_multas.index)\n","labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j340o3iJorG7"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(6, 6))\n","\n","# Asignar etiquetas a la tabla de multas y seleccionar los puntos que no forman parte de ningún clúster (ruido)\n","ruido = gdf_multas.assign(\n","    labels=labels\n",").query(\"labels == -1\")\n","\n","# Representar el ruido en color gris\n","ax.scatter(\n","    ruido[\"LONGITUD\"],\n","    ruido[\"LATITUD\"],\n","    c='grey',\n","    s=5,\n","    linewidth=0\n",")\n","\n","# Representar todos los puntos que no son ruido en rojo\n","ax.scatter(\n","    gdf_multas.loc[gdf_multas.index.difference(ruido.index), \"LONGITUD\"],\n","    gdf_multas.loc[gdf_multas.index.difference(ruido.index), \"LATITUD\"],\n","    c=\"red\",\n","    linewidth=0\n",")\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.PositronNoLabels\n",")\n","\n","# Mapear\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTTl_YTvo-RN"},"outputs":[],"source":["# Configurar el algoritmo DBSCAN\n","algo = DBSCAN(eps=500, min_samples=10)  # Mínimo 10 multas dentro de un radio de 500 metros\n","\n","# Ajustar a los puntos de las multas\n","algorit.fit(gdf_multas[[\"LONGITUD\", \"LATITUD\"]])\n","\n","# Almacenar etiquetas\n","labels = pd.Series(algorit.labels_, index=gdf_multas.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDnr04zQpmg8"},"outputs":[],"source":["# Establecer figura y ejes\n","f, ax = plt.subplots(1, figsize=(6, 6))\n","\n","# Asignar etiquetas a la tabla de multas y seleccionar los puntos que no forman parte de ningún clúster (ruido)\n","noise = gdf_multas.assign(\n","    labels=labels\n",").query(\"labels == -1\")\n","\n","# Representar el ruido en color gris\n","ax.scatter(\n","    noise[\"LONGITUD\"],\n","    noise[\"LATITUD\"],\n","    c='grey',\n","    s=5,\n","    linewidth=0\n",")\n","# Representar todos los puntos que no son ruido en rojo\n","ax.scatter(\n","    gdf_multas.loc[gdf_multas.index.difference(noise.index), \"LONGITUD\"],\n","    gdf_multas.loc[gdf_multas.index.difference(noise.index), \"LATITUD\"],\n","    c=\"red\",\n","    linewidth=0\n",")\n","\n","# Añadir mapa base\n","cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.PositronNoLabels\n",")\n","\n","# Mapear\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YjoVNlXiqKVs"},"outputs":[],"source":["def clusters(db, eps, min_samples):\n","    '''\n","    Calcula y visualiza los clústeres de DBSCAN\n","    ...\n","\n","    Argumentos\n","    ----------\n","    db          : (Geo)DataFrame\n","                  Tabla con al menos las columnas `X` y `Y` para las coordenadas de los puntos\n","    eps         : float\n","                  Radio máximo para buscar puntos dentro de un clúster\n","    min_samples : int\n","                  Número mínimo de puntos en un clúster\n","    '''\n","    # Congigurar algoritmo\n","    algo = DBSCAN(eps=eps, min_samples=min_samples)\n","    algo.fit(db[['LONGITUD', 'LATITUD']])\n","    lbls = pd.Series(algo.labels_, index=db.index)\n","\n","    # Representar todos los puntos según si son ruido o no ruido\n","    f, ax = plt.subplots(1, figsize=(6, 6))\n","    noise = db.loc[lbls==-1, ['LONGITUD', 'LATITUD']]\n","    ax.scatter(noise['LONGITUD'], noise['LATITUD'], c='grey', s=5, linewidth=0)\n","    ax.scatter(\n","        db.loc[db.index.difference(noise.index), 'LONGITUD'],\n","        db.loc[db.index.difference(noise.index), 'LATITUD'],\n","        c='red',\n","        linewidth=0\n","    )\n","\n","    # Añadir mapa base\n","    cx.add_basemap(\n","    ax,\n","    crs=\"EPSG:25830\",\n","    source=cx.providers.CartoDB.PositronNoLabels)\n","\n","    # Mapear\n","    return plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7oesU64qXN-"},"outputs":[],"source":["clusters(gdf_multas, 50, 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbHpw4Wcq2Ci"},"outputs":[],"source":["interact(\n","    clusters,                 # Método para hacerlo interactivo\n","    db=fixed(gdf_multas),     # Datos para pasar a db\n","    eps=(50, 500, 50),        # Rango de inicio, final y paso de distancia\n","    min_samples=(50, 300, 50) # Rango inicio, final y paso de muestras mínimas\n",")"]},{"cell_type":"markdown","source":["Visualizar gráfica del codo para elegir ϵ óptimo de manera visual"],"metadata":{"id":"nQ5UpSP14KIO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3x_0sl8SrMYU"},"outputs":[],"source":["# Definir el número de vecinos (minPts - 1)\n","minPts = 50  # comenzamos con 50\n","k = minPts - 1\n","\n","# Ajustar el modelo a los datos de multas\n","neigh = NearestNeighbors(n_neighbors=k)\n","neigh.fit(gdf_multas[['LONGITUD', 'LATITUD']])\n","\n","# Calcular distancias al k-ésimo vecino más cercano\n","distances, _ = neigh.kneighbors(gdf_multas[['LONGITUD', 'LATITUD']])\n","k_distances = np.sort(distances[:, k-1])[::-1]  # Ordenar de mayor a menor\n","\n","# Filtrar distancias mayores a 0\n","k_distances = k_distances[k_distances > 0]\n","\n","# Visualizar la curva del codo en el orden correcto\n","plt.figure(figsize=(12, 6))\n","plt.plot(range(1, len(k_distances) + 1), k_distances, marker='.', linestyle='-', label=\"Distancias ordenadas\")\n","\n","# Configuración del gráfico\n","plt.xlabel('Índice de puntos ordenados')\n","plt.ylabel(f'Distancia al {k}-ésimo vecino más cercano')\n","plt.title('Método del Codo para determinar $\\\\epsilon$ en DBSCAN')\n","plt.legend()\n","plt.grid(True)\n","\n","# Ajustar los ticks en el eje X para mayor claridad\n","plt.xticks(np.arange(0, len(k_distances) + 1, step=200))\n","\n","# Mostrar gráfico\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yBCAszzrYQL"},"outputs":[],"source":["# Cargar datos de multas en Madrid\n","data = gdf_multas[['LONGITUD', 'LATITUD']].values\n","\n","# Definir valores de epsilon y minPts\n","eps_values = [100, 500, 5]\n","minPts_values = [400, 700, 1000]\n","\n","fig, axes = plt.subplots(len(minPts_values), len(eps_values), figsize=(15, 8))\n","\n","for i, minPts in enumerate(minPts_values):\n","    for j, eps in enumerate(eps_values):\n","        db = DBSCAN(eps=eps, min_samples=minPts).fit(data)\n","        labels = db.labels_\n","        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # No cuenta ruido (-1)\n","\n","        # Usar colores de la paleta \"tab10\" con color negro para ruido\n","        unique_labels = set(labels)\n","        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n","        color_dict = {label: color for label, color in zip(unique_labels, colors)}\n","        color_dict[-1] = 'black'  # Ruido en negro\n","\n","        # Aplicar colores personalizados\n","        cluster_colors = [color_dict[label] for label in labels]\n","\n","        # Graficar puntos coloreados por clúster\n","        axes[i, j].scatter(data[:, 0], data[:, 1], c=cluster_colors, s=5, alpha=0.6, edgecolors='k', linewidth=0.1)\n","        axes[i, j].set_title(f\"ε={eps:.2f}, minPts={minPts}\\nClústeres={n_clusters}\", fontsize=9, pad=8)\n","        axes[i, j].set_xticks([])\n","        axes[i, j].set_yticks([])\n","\n","# Ajustar espacio entre gráficos para evitar solapamientos\n","plt.subplots_adjust(hspace=0.4, wspace=0.3)\n","\n","# Mostrar gráfico\n","plt.show()"]},{"cell_type":"markdown","source":["Índice silhouette para comprobar la bondad de la clusterización"],"metadata":{"id":"Zt5Czmftfsq9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9RRL1ndvrmuF"},"outputs":[],"source":["# Excluir ruido (-1) de DBSCAN antes de calcular el índice: con epsilon de 170 y con minPts de 70\n","mask = labels != -1\n","score = silhouette_score(gdf_multas[['LONGITUD', 'LATITUD']][mask], labels[mask])\n","print(f\"Índice de Silhouette: {score:.3f}\")"]},{"cell_type":"markdown","source":["Al ser valor 1, las observaciones dentro de cada clúster están perfectamente agrupadas y cada grupo está correctamente separado del resto."],"metadata":{"id":"hCm6xS3o8gGN"}},{"cell_type":"markdown","metadata":{"id":"ak75zC0whVNY"},"source":["**Anexo. Uso de algoritmos de clasificación.**\n"]},{"cell_type":"markdown","metadata":{"id":"v7eHxWMHllfS"},"source":["Una vez explorados los datos desde distintos puntos de vista, una posibilidad interesante es clasificar los datos. Para ello existen diversos algoritmos que se pueden utilizar como las redes neuronales, las máquinas vector soporte (SVM), los árboles de decisión o random forest. Para generar estas clasificaciones hemos utilizado la documentación oficial de [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)."]},{"cell_type":"markdown","metadata":{"id":"xRr-FRIpmBXy"},"source":["En primer lugar vamos a probar a realizar una clasificación mediante árboles de decisión. Para ello tomamos como variables predictoras el distrito, año, mes y número de delitos (serán las mismas variables predictoras en el resto de algoritmos) y como variable objetivo o variable a predecir es el riesgo que presenta la zona, que según el número de delitos que ha presentado una zona respecto a la media se considera de Alto riesgo (33% de los valores más altos), Bajo riesgo (33% de los valores mas bajos) y Riesgo Medio (resto de valores).\n","\n","Según el tipo de delito, la clasificación cambia, indicando que hay zonas muy seguras en general, otras que son peligras para todo tipo de delitos y algunas en las que ciertos tipos de delitos son predominantes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TSIgdRQhUre"},"outputs":[],"source":["# Codificar los distritos como números\n","le = LabelEncoder()\n","df_union[\"distrito_cod\"] = le.fit_transform(df_union[\"DISTRITOS\"])\n","# Añadir variables de mes y año para añadirlas como variables\n","df_union[\"año\"] = df_union[\"Fecha\"].dt.year\n","df_union[\"mes\"] = df_union[\"Fecha\"].dt.month"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"monaBjCypr_Y"},"outputs":[],"source":["# Función de clasificación\n","def clasificar_delito(tipo_delito):\n","\n","    # Calcular percentiles para el tipo de delito seleccionado\n","    percentil_bajo = np.percentile(df_union[tipo_delito], 33)  # 33% de los valores más bajos\n","    percentil_alto = np.percentile(df_union[tipo_delito], 66)  # 33% de los valores más altos\n","\n","    # Clasificar los distritos en base a los percentiles de delitos\n","    def clasificar_distrito(row):\n","        if row[tipo_delito] > percentil_alto:\n","            return 'Alto riesgo'\n","        elif row[tipo_delito] > percentil_bajo:\n","            return 'Riesgo medio'\n","        else:\n","            return 'Bajo riesgo'\n","\n","    # Crear la variable objetivo clasificando los distritos\n","    df_union['clasificacion'] = df_union.apply(clasificar_distrito, axis=1)\n","\n","    # Preprocesar la variable objetivo utilizando LabelEncoder\n","    le = LabelEncoder()\n","    y = df_union['clasificacion']\n","    y = le.fit_transform(y)  # Codificar categorías a números\n","\n","    # Definir las variables predictoras (X)\n","    X = df_union[[\"distrito_cod\", \"año\", \"mes\", tipo_delito]]\n","\n","    # Dividir los datos en entrenamiento y prueba\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Entrenar el modelo de clasificación\n","    modelo = DecisionTreeClassifier(max_depth=5, random_state=42)\n","    modelo.fit(X_train, y_train)\n","\n","    # Hacer predicciones en todo el conjunto de datos\n","    df_union[\"prediccion\"] = modelo.predict(X)\n","\n","    # Invertir la transformación del LabelEncoder para obtener las etiquetas originales\n","    df_union[\"prediccion\"] = le.inverse_transform(df_union[\"prediccion\"])\n","\n","    # Graficar el mapa\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","    df_union.plot(column=\"prediccion\", cmap=\"tab10\", legend=True, ax=ax, edgecolor=\"black\")\n","\n","    # Agregar nombres de los distritos en el mapa\n","    for x, y, label in zip(df_union.geometry.centroid.x, df_union.geometry.centroid.y, df_union[\"DISTRITOS\"]):\n","        ax.text(x, y, label, fontsize=8, ha=\"center\", color=\"black\")\n","\n","    ax.set_title(f\"Mapa de clasificación por árboles de decisión para {tipo_delito}\", fontsize=14)\n","    ax.axis(\"off\")  # Ocultar ejes\n","\n","    plt.show()\n","\n","# Crear el widget interactivo para seleccionar el tipo de delito\n","interact(clasificar_delito, tipo_delito=widgets.Dropdown(options=delitos, description=\"Delito:\"));\n"]},{"cell_type":"markdown","metadata":{"id":"wrA3fh4L0sHH"},"source":["A continuación, realizamos la misma clasificación con otro algoritmo, el random forest. Este algoritmo es muy utilizado en muchos campos y es más robusto que los árboles de decisión. Sin embargo, cuenta con una desventaja respecto a los árboles de decisión, y es que no se pueden ver los nodos. Sin embargo, en el ejemplo utilizando árbol de decisión no se han mostrado los nodos y ramas del árbol porque había muchos y la visualización era bastante mala.\n","\n","Dicho esto, los resultados con random forest son bastante similares a los obtenidos mediante árboles de decisión."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yY9UG15jqi8h"},"outputs":[],"source":["# Definir la función de clasificación\n","def clasificar_delito(tipo_delito):\n","\n","    # Calcular percentiles para el tipo de delito seleccionado\n","    percentil_bajo = np.percentile(df_union[tipo_delito], 33)  # 33% de los valores más bajos\n","    percentil_alto = np.percentile(df_union[tipo_delito], 66)  # 33% de los valores más altos\n","\n","    # Clasificar los distritos en base a los percentiles de delitos\n","    def clasificar_distrito(row):\n","        if row[tipo_delito] > percentil_alto:\n","            return 'Alto riesgo'\n","        elif row[tipo_delito] > percentil_bajo:\n","            return 'Riesgo medio'\n","        else:\n","            return 'Bajo riesgo'\n","\n","    # Crear la variable objetivo clasificando los distritos\n","    df_union['clasificacion'] = df_union.apply(clasificar_distrito, axis=1)\n","\n","    # Preprocesar la variable objetivo utilizando LabelEncoder\n","    le = LabelEncoder()\n","    y = df_union['clasificacion']\n","    y = le.fit_transform(y)  # Codificar categorías a números\n","\n","    # Definir las variables predictoras (X)\n","    X = df_union[[\"distrito_cod\", \"año\", \"mes\", tipo_delito]]\n","\n","    # Dividir los datos en entrenamiento y prueba\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Entrenar el modelo de Random Forest\n","    modelo = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n","    modelo.fit(X_train, y_train)\n","\n","    # Hacer predicciones en todo el conjunto de datos\n","    df_union[\"prediccion\"] = modelo.predict(X)\n","\n","    # Invertir la transformación del LabelEncoder para obtener las etiquetas originales\n","    df_union[\"prediccion\"] = le.inverse_transform(df_union[\"prediccion\"])\n","\n","    # Graficar el mapa\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","    df_union.plot(column=\"prediccion\", cmap=\"tab10\", legend=True, ax=ax, edgecolor=\"black\")\n","\n","    # Agregar nombres de los distritos en el mapa\n","    for x, y, label in zip(df_union.geometry.centroid.x, df_union.geometry.centroid.y, df_union[\"DISTRITOS\"]):\n","        ax.text(x, y, label, fontsize=8, ha=\"center\", color=\"black\")\n","\n","    ax.set_title(f\"Mapa de clasificación con random forest para {tipo_delito}\", fontsize=14)\n","    ax.axis(\"off\")  # Ocultar ejes\n","\n","    plt.show()\n","\n","# Crear el widget interactivo para seleccionar el tipo de delito\n","interact(clasificar_delito, tipo_delito=widgets.Dropdown(options=delitos, description=\"Delito:\"));\n"]},{"cell_type":"markdown","metadata":{"id":"grmQUxYr1g8O"},"source":["Después, hacemos una prueba con el algoritmo de redes neuronales. A diferencia de los casos anteriores, los resultados han variado más hasta el punto de que si nos fijamos en la clasificación . Es importante tener en cuenta que para este algoritmo hay que ajustar bien algunos parámetros como el número de capas de neuronas, el número de neuronas o la tasa de crecimiento para obtener los mejores resultados y evitar problemas como el sobreajuste."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxyK63A9q3LY"},"outputs":[],"source":["# Definir la función de clasificación\n","def clasificar_delito(tipo_delito):\n","\n","    # Calcular percentiles para el tipo de delito seleccionado\n","    percentil_bajo = np.percentile(df_union[tipo_delito], 33)  # 33% de los valores más bajos\n","    percentil_alto = np.percentile(df_union[tipo_delito], 66)  # 33% de los valores más altos\n","\n","    # Clasificar los distritos en base a los percentiles de delitos\n","    def clasificar_distrito(row):\n","        if row[tipo_delito] > percentil_alto:\n","            return 'Alto riesgo'\n","        elif row[tipo_delito] > percentil_bajo:\n","            return 'Riesgo medio'\n","        else:\n","            return 'Bajo riesgo'\n","\n","    # Crear la variable objetivo clasificando los distritos\n","    df_union['clasificacion'] = df_union.apply(clasificar_distrito, axis=1)\n","\n","    # Preprocesar la variable objetivo utilizando LabelEncoder\n","    le = LabelEncoder()\n","    y = df_union['clasificacion']\n","    y = le.fit_transform(y)  # Codificar categorías a números\n","\n","    # Definir las variables predictoras (X)\n","    X = df_union[[\"distrito_cod\", \"año\", \"mes\", tipo_delito]]\n","\n","    # Dividir los datos en entrenamiento y prueba\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Entrenar el modelo de Red Neuronal (MLP)\n","    modelo = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n","    modelo.fit(X_train, y_train)\n","\n","    # Hacer predicciones en todo el conjunto de datos\n","    df_union[\"prediccion\"] = modelo.predict(X)\n","\n","    # Invertir la transformación del LabelEncoder para obtener las etiquetas originales\n","    df_union[\"prediccion\"] = le.inverse_transform(df_union[\"prediccion\"])\n","\n","    # Graficar el mapa\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","    df_union.plot(column=\"prediccion\", cmap=\"tab10\", legend=True, ax=ax, edgecolor=\"black\")\n","\n","    # Agregar nombres de los distritos en el mapa\n","    for x, y, label in zip(df_union.geometry.centroid.x, df_union.geometry.centroid.y, df_union[\"DISTRITOS\"]):\n","        ax.text(x, y, label, fontsize=8, ha=\"center\", color=\"black\")\n","\n","    ax.set_title(f\"Mapa de clasificación con redes neuronales (MLP) para {tipo_delito}\", fontsize=14)\n","    ax.axis(\"off\")  # Ocultar ejes\n","\n","    plt.show()\n","\n","# Crear el widget interactivo para seleccionar el tipo de delito\n","interact(clasificar_delito, tipo_delito=widgets.Dropdown(options=delitos, description=\"Delito:\"));\n"]},{"cell_type":"markdown","metadata":{"id":"t5tIfF0U4_MN"},"source":["Por último, realizamos una clasifiación mediante SVM. Al igual que en el caso anterior, los resultados obtenidos han sido muy diferentes respecto a los de los otros algoritmos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yU0o7jqerSHp"},"outputs":[],"source":["# Definir la función de clasificación\n","def clasificar_delito(tipo_delito):\n","\n","    # Calcular percentiles para el tipo de delito seleccionado\n","    percentil_bajo = np.percentile(df_union[tipo_delito], 33)  # 33% de los valores más bajos\n","    percentil_alto = np.percentile(df_union[tipo_delito], 66)  # 33% de los valores más altos\n","\n","    # Clasificar los distritos en base a los percentiles de delitos\n","    def clasificar_distrito(row):\n","        if row[tipo_delito] > percentil_alto:\n","            return 'Alto riesgo'\n","        elif row[tipo_delito] > percentil_bajo:\n","            return 'Riesgo medio'\n","        else:\n","            return 'Bajo riesgo'\n","\n","    # Crear la variable objetivo clasificando los distritos\n","    df_union['clasificacion'] = df_union.apply(clasificar_distrito, axis=1)\n","\n","    # Preprocesar la variable objetivo utilizando LabelEncoder\n","    le = LabelEncoder()\n","    y = df_union['clasificacion']\n","    y = le.fit_transform(y)  # Codificar categorías a números\n","\n","    # Definir las variables predictoras (X)\n","    X = df_union[[\"distrito_cod\", \"año\", \"mes\", tipo_delito]]\n","\n","    # Dividir los datos en entrenamiento y prueba\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Entrenar el modelo de SVM\n","    modelo = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n","    modelo.fit(X_train, y_train)\n","\n","    # Hacer predicciones en todo el conjunto de datos\n","    df_union[\"prediccion\"] = modelo.predict(X)\n","\n","    # Invertir la transformación del LabelEncoder para obtener las etiquetas originales\n","    df_union[\"prediccion\"] = le.inverse_transform(df_union[\"prediccion\"])\n","\n","    # Graficar el mapa\n","    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n","    df_union.plot(column=\"prediccion\", cmap=\"tab10\", legend=True, ax=ax, edgecolor=\"black\")\n","\n","    # Agregar nombres de los distritos en el mapa\n","    for x, y, label in zip(df_union.geometry.centroid.x, df_union.geometry.centroid.y, df_union[\"DISTRITOS\"]):\n","        ax.text(x, y, label, fontsize=8, ha=\"center\", color=\"black\")\n","\n","    ax.set_title(f\"Mapa de clasificación con SVM para {tipo_delito}\", fontsize=14)\n","    ax.axis(\"off\")  # Ocultar ejes\n","\n","    plt.show()\n","\n","\n","# Crear el widget interactivo para seleccionar el tipo de delito\n","interact(clasificar_delito, tipo_delito=widgets.Dropdown(options=delitos, description=\"Delito:\"));\n"]},{"cell_type":"markdown","metadata":{"id":"uDB9yOHcy7wO"},"source":["Como se puede observar, el tipo de algoritmo ha hecho que los resultados varíen mucho. Esto solo es una prueba para realizar clasificaciones y si quisieramos realizar una clasificación mejor deberíamos modificar parámmetros de los algoritmos como el número de neuronas de la red neuronal, C (Parámetro de penalización del error en SVM) o la profundidad del árbol en los árboles de decisión y en random forest. Además, para poder utilizar estas clasificaciones en otros estudios deberíamos validarlas con otros datos, ya que aunque los algoritmos utilizados utilizan una parte de los datos proporcionados para validar, al ser datos extraídos de la misma fuente pueden estar sesgados.\n","\n","Por ello, no sacaremos ninguna conclusión de los resultados obtenidos a partir de estas clasificaciones porque no tenemos la certeza de que algunos de ellos sea correcto."]},{"cell_type":"markdown","source":["**Conclusiones extraídas de los resultados**"],"metadata":{"id":"mvSVyYrLIrTm"}},{"cell_type":"markdown","source":["Como se ha podido observar en este ESDA, la mayoría de los delitos, independientemente de la fecha, no presentan autocorrelación global estadísticamente significativa. En cuanto a la autocorrelación local, si que está presente y es muy diferente según el tipo de delito y la fecha que estemos estudiando.\n","\n","Por otra parte, si nos fijamos en la agrupación de zonas según los delitos y la comparamos con las divisiones administrativas reales, podemos ver que son muy diferentes entre sí. Este resultado podría ser útil de cara a luchar contra ciertos crímenes o para la distribución de las fuerzas de seguridad en la ciudad de Madrid.\n","\n","Por último, del análisis de patrones de puntos realizado sobre los datos de multas en Madrid podemos extraer que las multas se pueden agrupar en clústeres, lo que podría estar indicando que hay zonas más problemáticas en este sentido."],"metadata":{"id":"dI8nuTqyIx0e"}},{"cell_type":"markdown","metadata":{"id":"vwP9l-_VSJQk"},"source":["## **5. Evaluación crítica**"]},{"cell_type":"markdown","metadata":{"id":"qhztfyO1UDn7"},"source":["Antes de tomar los resultados obtenidos en este análisis exploratorio de datos como definitivos es importante tener en cuenta las debilidades y fortalezas del mismo.\n","\n","Comenzando por las debilidades, al igual que sucedía en el EDA realizado previamente y aunque se han incluido más fuentes de datos, sigue siendo interesante la inclusión de otras variables que podrían ser interesantes en este estudio como la renta media por persona, el nivel de estudios medios por persona o porcentaje de personas en el paro entre otros muchos ejemplos. Otra posible debilidad es que, aunque hemos utilizado dos tipos de datos (datos puntuales y distritos de Madrid), quizá podría ser interesante hacer este mismo análisis a otras escalas. Por ejemplo a nivel de barrio o incluso de calle, lo que nos permitiría darle otro enfoque al trabajo y comprender mejor la distribución de los delitos en la ciudad de Madrid.  Otra posible debilidad es que no se han comparado los resultados obtenidos con los de otro ESDA similar, ya que no hemos podido encontrar ninguno parecido. Esto nos habría permitido \"validar\" nuestros resultados, encontrar fallos o fuentes de error y mejorar nuestro ESDA. En cuanto a las estadísticas relativas a las multas de tráfico, la limpieza de los datos no fue sencilla, ya que habían coordenadas vacías y también coordenadas incorrectas. Además, muchas de las coordenadas estaban repetidas, es decir, en la misma coordenada hay datos de varias multas, lo cual puede deberse a la propia naturaleza del hecho o una incorrecta transposición de las coordenadas al crear la base de datos.\n","\n","\n","En cuanto a las fortalezas, los datos de partida son fiables ya que se han extraido de instituciones oficiales como el Ayuntamiento de Madrid. Además, existe continuidad en los datos, lo que nos permite estudiar la evolución de los delitos sin riesgo a que la falta de datos sesgue nuestros resultados. Otra fortaleza del estudio es que como los datos están divididos en función de distritos, nos permiten ver diferencias dentro de la ciudad de Madrid y dan pie a realizar un analisis espacial de los datos en el futuro. También es una fortaleza que los datos cubran todos los distritos de la ciudad, ya que esto significa que la cobertura espacial de la zona objetivo de estudio es total. Por último, una gran fortaleza del estudio es que se han podido responder, en mayor o menor medida, las preguntas que nos hemos planteado al inicio del estudio, permitiendonos cumplir nuestros objetivos iniciales."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python (advprog)","language":"python","name":"advprog"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":0}